{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDSN_ShipCrew Linear Regression",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/BDSN_ShipCrew_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSccZgVu7J8"
      },
      "source": [
        "![CC-BY-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)<br>\n",
        "<hr>\n",
        "\n",
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('Tested',datetime.now(pytz.timezone('Asia/Calcutta')))"
      ],
      "metadata": {
        "id": "yy2REumumhvw",
        "outputId": "38a4c9db-18ca-4297-8681-41d0218229fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested 2024-07-03 09:18:28.757103+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-6MzHBr88H"
      },
      "source": [
        "# BDSN Ship Crews <br>\n",
        "https://www.geeksforgeeks.org/pyspark-linear-regression-using-apache-mllib/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqGXJ8DIxzWN"
      },
      "source": [
        "# Initialise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deprecated -- do not use"
      ],
      "metadata": {
        "id": "HICvwwOMsbcj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr826zIx3Kh"
      },
      "source": [
        "#!apt-get update > /dev/null\n",
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "#!pip install -q pyspark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_l58UKyQ65"
      },
      "source": [
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Spark, current version"
      ],
      "metadata": {
        "id": "ZLTIcLnstJT_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3hdu86YyVEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "190be50d-d73f-4a31-d652-bd9960b37674"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "!pip3 install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Praxis_Shipping').master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=Praxis_Shipping>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://72a9237e2e85:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Praxis_Shipping</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPnrUzlSsLN2"
      },
      "source": [
        "# Load Data <br>\n",
        "Data is available at https://drive.google.com/file/d/1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW476lcv5SGE"
      },
      "source": [
        "# Get Data\n",
        "#!gdown https://drive.google.com/uc?id=1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw\n",
        "!wget -q 'https://raw.githubusercontent.com/Praxis-QR/BDSN/main/data/ML/ShippingCrewInfo.csv'\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds4N6HfQszq7"
      },
      "source": [
        "#!ls -al"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_df=spark.read.csv('/content/ShippingCrewInfo.csv',inferSchema=True,header=True)\n",
        "crew_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3vO6Zq1Ue62",
        "outputId": "bdfa51e1-5bc4-425d-f16d-86e38af9d6e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints structure of dataframe along with datatype\n",
        "crew_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu2pMQ_CU4_X",
        "outputId": "3df610ce-b2ee-4228-8774-b24cf542cda3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Tonnage: double (nullable = true)\n",
            " |-- passengers: double (nullable = true)\n",
            " |-- length: double (nullable = true)\n",
            " |-- cabins: double (nullable = true)\n",
            " |-- passenger_density: double (nullable = true)\n",
            " |-- crew: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing : Indexing, Vectorising"
      ],
      "metadata": {
        "id": "5XmoRY_NWc4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns identified as features are as below:\n",
        "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
        "#to work on the features, spark MLlib expects every value to be in numeric form\n",
        "#feature 'Cruise_line is string datatype\n",
        "#using StringIndexer, string type will be typecast to numeric datatype\n",
        "#import library strinindexer for typecasting\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol='Cruise_line',outputCol='cruise_cat')\n",
        "crew_df2 = indexer.fit(crew_df).transform(crew_df)                        # indexer.fit(crew_df) is a Transformer\n",
        "\n",
        "#above code will convert string to numeric feature and create a new dataframe\n",
        "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
        "#feature cruise_cat is now vectorized and can be used to fed to model\n",
        "crew_df2.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQpXOeAXVMSX",
        "outputId": "f2d4353b-bf73-41a4-be60-54d72fcf8354"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "#creating vectors from features\n",
        "#Apache MLlib takes input if vector form\n",
        "assembler=VectorAssembler(inputCols=['Age',\n",
        " 'Tonnage',\n",
        " 'passengers',\n",
        " 'length',\n",
        " 'cabins',\n",
        " 'passenger_density',\n",
        " 'cruise_cat'],outputCol='features')\n",
        "crew_df3=assembler.transform(crew_df2)                              # assember is a Transformer\n",
        "crew_df3.head(3)\n",
        "#crew_df3.select('features','crew').show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWK8Ww8sWx5j",
        "outputId": "61b99ad0-0e01-493b-ab64-7c0d6e07b83b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0, features=DenseVector([26.0, 47.262, 14.86, 7.22, 7.43, 31.8, 1.0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final data consist of features and label which is crew.\n",
        "data=crew_df3.select('features','crew')\n",
        "#splitting data into train and test\n",
        "train_data,test_data=data.randomSplit([0.7,0.3])\n",
        "train_data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3PZN_AXukO",
        "outputId": "d2274762-2797-42ba-f199-607eaf369209"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|              crew|\n",
            "+-------+------------------+\n",
            "|  count|               108|\n",
            "|   mean| 7.663888888888899|\n",
            "| stddev|3.5464972408177236|\n",
            "|    min|              0.59|\n",
            "|    max|              21.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "Read this https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html"
      ],
      "metadata": {
        "id": "KZ4pU5e0YRCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import LinearRegression library\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "#creating an object of class LinearRegression\n",
        "#object takes features and label as input arguments\n",
        "ship_lr=LinearRegression(featuresCol='features',labelCol='crew')\n",
        "#pass train_data to train model\n",
        "trained_ship_model=ship_lr.fit(train_data)                     # trained_ship_model, a TRAINED model, is a Transformer\n",
        "#evaluating model trained for Rsquared error\n",
        "ship_results=trained_ship_model.evaluate(train_data)\n",
        "\n",
        "print('Rsquared Error :',ship_results.r2)\n",
        "#R2 value shows accuracy of model is 92%\n",
        "#model accuracy is very good and can be use for predictive analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQzHX87nYd6-",
        "outputId": "fc4ad48b-1546-4b8a-ea9b-5f365eb268a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rsquared Error : 0.9631240296093722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "79KsT9AGZGVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Unlabelled Data"
      ],
      "metadata": {
        "id": "XCdxTnR6bUu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing Model on unlabeled data\n",
        "#create unlabeled data from test_data\n",
        "#testing model on unlabeled data\n",
        "unlabeled_data=test_data.select('features')\n",
        "unlabeled_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lue3EJ5ZIRF",
        "outputId": "88f33d0c-d0e6-445f-dc35-5b70f09652f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[5.0,86.0,21.04,9...|\n",
            "|[6.0,93.0,23.94,9...|\n",
            "|[6.0,112.0,38.0,9...|\n",
            "|[6.0,113.0,37.82,...|\n",
            "|[7.0,116.0,31.0,9...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trained_ship_model.transform(unlabeled_data)      # the Transformer, trained_ship_model, is transforming data, unlabelled_data\n",
        "predictions.show()\n",
        "#below are the results of output from test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN5eHyZjaowH",
        "outputId": "d80fe115-0a90-4fcf-d225-b046eebe2b1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|        prediction|\n",
            "+--------------------+------------------+\n",
            "|[5.0,86.0,21.04,9...| 9.184052305041378|\n",
            "|[6.0,93.0,23.94,9...| 10.39424962854118|\n",
            "|[6.0,112.0,38.0,9...| 11.12926453176487|\n",
            "|[6.0,113.0,37.82,...| 11.46482673052301|\n",
            "|[7.0,116.0,31.0,9...|12.396928501494902|\n",
            "|[8.0,91.0,22.44,9...| 9.973799992475103|\n",
            "|[9.0,110.0,29.74,...|11.880535456324269|\n",
            "|[9.0,113.0,26.74,...|11.227368441815727|\n",
            "|[9.0,116.0,26.0,9...|11.091251474081988|\n",
            "|[10.0,58.825,15.6...| 7.192618787754309|\n",
            "|[10.0,77.0,20.16,...| 8.650554619929116|\n",
            "|[10.0,110.0,29.74...|11.867608038857785|\n",
            "|[11.0,90.0,22.4,9...| 9.922009532334204|\n",
            "|[11.0,91.62700000...| 9.192093997055846|\n",
            "|[11.0,110.0,29.74...| 11.87467413157462|\n",
            "|[11.0,138.0,31.14...|12.890559360820149|\n",
            "|[12.0,25.0,3.88,5...|3.0360934694129003|\n",
            "|[12.0,58.6,15.66,...|  7.30385647309023|\n",
            "|[12.0,88.5,21.24,...|10.213471947743997|\n",
            "|[12.0,91.0,20.32,...| 9.191730936201672|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Labelled Data"
      ],
      "metadata": {
        "id": "8weWV82Fbbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted2 = trained_ship_model.transform(test_data)          # the Transformer, trained_ship_model, is transforming data, test_data\n",
        "predicted2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnzAeWx6a-gn",
        "outputId": "6beea250-2652-4adb-bdf2-d3c685043c8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|        prediction|\n",
            "+--------------------+-----+------------------+\n",
            "|[5.0,86.0,21.04,9...|  8.0| 9.184052305041378|\n",
            "|[6.0,93.0,23.94,9...|11.09| 10.39424962854118|\n",
            "|[6.0,112.0,38.0,9...| 10.9| 11.12926453176487|\n",
            "|[6.0,113.0,37.82,...| 12.0| 11.46482673052301|\n",
            "|[7.0,116.0,31.0,9...| 12.0|12.396928501494902|\n",
            "|[8.0,91.0,22.44,9...| 11.0| 9.973799992475103|\n",
            "|[9.0,110.0,29.74,...| 11.6|11.880535456324269|\n",
            "|[9.0,113.0,26.74,...|12.38|11.227368441815727|\n",
            "|[9.0,116.0,26.0,9...| 11.0|11.091251474081988|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.192618787754309|\n",
            "|[10.0,77.0,20.16,...|  9.0| 8.650554619929116|\n",
            "|[10.0,110.0,29.74...| 11.6|11.867608038857785|\n",
            "|[11.0,90.0,22.4,9...| 11.0| 9.922009532334204|\n",
            "|[11.0,91.62700000...|  9.0| 9.192093997055846|\n",
            "|[11.0,110.0,29.74...| 19.1| 11.87467413157462|\n",
            "|[11.0,138.0,31.14...|11.85|12.890559360820149|\n",
            "|[12.0,25.0,3.88,5...| 2.87|3.0360934694129003|\n",
            "|[12.0,58.6,15.66,...|  7.0|  7.30385647309023|\n",
            "|[12.0,88.5,21.24,...|  9.3|10.213471947743997|\n",
            "|[12.0,91.0,20.32,...| 9.99| 9.191730936201672|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_ship_model.setPredictionCol(\"PraxisPredictions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUcIm5V0dErB",
        "outputId": "63a90471-b2e8-4d16-8626-c310b618dd30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel: uid=LinearRegression_1139feb839ef, numFeatures=7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted3 = trained_ship_model.transform(test_data)\n",
        "predicted3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNmdSX5dSOr",
        "outputId": "73fb90d9-b692-4970-fe6d-0eaa005c41bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|PraxisPredictions!|\n",
            "+--------------------+-----+------------------+\n",
            "|[5.0,86.0,21.04,9...|  8.0| 9.184052305041378|\n",
            "|[6.0,93.0,23.94,9...|11.09| 10.39424962854118|\n",
            "|[6.0,112.0,38.0,9...| 10.9| 11.12926453176487|\n",
            "|[6.0,113.0,37.82,...| 12.0| 11.46482673052301|\n",
            "|[7.0,116.0,31.0,9...| 12.0|12.396928501494902|\n",
            "|[8.0,91.0,22.44,9...| 11.0| 9.973799992475103|\n",
            "|[9.0,110.0,29.74,...| 11.6|11.880535456324269|\n",
            "|[9.0,113.0,26.74,...|12.38|11.227368441815727|\n",
            "|[9.0,116.0,26.0,9...| 11.0|11.091251474081988|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.192618787754309|\n",
            "|[10.0,77.0,20.16,...|  9.0| 8.650554619929116|\n",
            "|[10.0,110.0,29.74...| 11.6|11.867608038857785|\n",
            "|[11.0,90.0,22.4,9...| 11.0| 9.922009532334204|\n",
            "|[11.0,91.62700000...|  9.0| 9.192093997055846|\n",
            "|[11.0,110.0,29.74...| 19.1| 11.87467413157462|\n",
            "|[11.0,138.0,31.14...|11.85|12.890559360820149|\n",
            "|[12.0,25.0,3.88,5...| 2.87|3.0360934694129003|\n",
            "|[12.0,58.6,15.66,...|  7.0|  7.30385647309023|\n",
            "|[12.0,88.5,21.24,...|  9.3|10.213471947743997|\n",
            "|[12.0,91.0,20.32,...| 9.99| 9.191730936201672|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "CBbIGsHfqQHN",
        "outputId": "79cf9338-553e-4851-eae4-9ba5b3a665c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2024-07-03 09:20:11.429776+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE1gjD5yNfrO"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself.\n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}