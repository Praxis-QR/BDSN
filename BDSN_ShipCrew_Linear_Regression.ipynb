{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDSN_ShipCrew Linear Regression",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/BDSN_ShipCrew_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSccZgVu7J8"
      },
      "source": [
        "![CC-BY-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)<br>\n",
        "<hr>\n",
        "\n",
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('Tested',datetime.now(pytz.timezone('Asia/Calcutta')))"
      ],
      "metadata": {
        "id": "yy2REumumhvw",
        "outputId": "15f14d9a-bc1f-4dc0-e7a9-71393080e50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested 2023-06-18 06:51:20.408055+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-6MzHBr88H"
      },
      "source": [
        "# BDSN Ship Crews <br>\n",
        "https://www.geeksforgeeks.org/pyspark-linear-regression-using-apache-mllib/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqGXJ8DIxzWN"
      },
      "source": [
        "# Initialise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deprecated -- do not use"
      ],
      "metadata": {
        "id": "HICvwwOMsbcj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr826zIx3Kh"
      },
      "source": [
        "#!apt-get update > /dev/null\n",
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "#!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_l58UKyQ65"
      },
      "source": [
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Spark, current version"
      ],
      "metadata": {
        "id": "ZLTIcLnstJT_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3hdu86YyVEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "d3301d4f-9e9b-4b45-d83f-920478869a85"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "!pip3 install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Praxis_Shipping').master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=Praxis_Shipping>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4b70b15ed613:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Praxis_Shipping</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPnrUzlSsLN2"
      },
      "source": [
        "# Load Data <br>\n",
        "Data is available at https://drive.google.com/file/d/1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW476lcv5SGE"
      },
      "source": [
        "# Get Data\n",
        "#!gdown https://drive.google.com/uc?id=1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw\n",
        "!wget -q 'https://raw.githubusercontent.com/Praxis-QR/BDSN/main/data/ML/ShippingCrewInfo.csv'\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds4N6HfQszq7"
      },
      "source": [
        "#!ls -al"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_df=spark.read.csv('/content/ShippingCrewInfo.csv',inferSchema=True,header=True)\n",
        "crew_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3vO6Zq1Ue62",
        "outputId": "613aa3cf-2a28-415f-e6d2-894b38b5e7e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints structure of dataframe along with datatype\n",
        "crew_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu2pMQ_CU4_X",
        "outputId": "77ab1df9-a761-4601-ed8b-5e492a13d2a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Tonnage: double (nullable = true)\n",
            " |-- passengers: double (nullable = true)\n",
            " |-- length: double (nullable = true)\n",
            " |-- cabins: double (nullable = true)\n",
            " |-- passenger_density: double (nullable = true)\n",
            " |-- crew: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing : Indexing, Vectorising"
      ],
      "metadata": {
        "id": "5XmoRY_NWc4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns identified as features are as below:\n",
        "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
        "#to work on the features, spark MLlib expects every value to be in numeric form\n",
        "#feature 'Cruise_line is string datatype\n",
        "#using StringIndexer, string type will be typecast to numeric datatype\n",
        "#import library strinindexer for typecasting\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol='Cruise_line',outputCol='cruise_cat')\n",
        "crew_df2 = indexer.fit(crew_df).transform(crew_df)                        # indexer.fit(crew_df) is a Transformer\n",
        "\n",
        "#above code will convert string to numeric feature and create a new dataframe\n",
        "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
        "#feature cruise_cat is now vectorized and can be used to fed to model\n",
        "crew_df2.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQpXOeAXVMSX",
        "outputId": "e9f9cf15-7743-496d-e1f1-a28e68dcba8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "#creating vectors from features\n",
        "#Apache MLlib takes input if vector form\n",
        "assembler=VectorAssembler(inputCols=['Age',\n",
        " 'Tonnage',\n",
        " 'passengers',\n",
        " 'length',\n",
        " 'cabins',\n",
        " 'passenger_density',\n",
        " 'cruise_cat'],outputCol='features')\n",
        "crew_df3=assembler.transform(crew_df2)                              # assember is a Transformer\n",
        "crew_df3.head(3)\n",
        "#crew_df3.select('features','crew').show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWK8Ww8sWx5j",
        "outputId": "0c0b3a7e-4e28-4abd-ccb2-424b13630865"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0, features=DenseVector([26.0, 47.262, 14.86, 7.22, 7.43, 31.8, 1.0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final data consist of features and label which is crew.\n",
        "data=crew_df3.select('features','crew')\n",
        "#splitting data into train and test\n",
        "train_data,test_data=data.randomSplit([0.7,0.3])\n",
        "train_data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3PZN_AXukO",
        "outputId": "31ffcaef-1268-4f84-8f51-ccae7795308f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|             crew|\n",
            "+-------+-----------------+\n",
            "|  count|              116|\n",
            "|   mean|7.906810344827598|\n",
            "| stddev|3.553648363886462|\n",
            "|    min|             0.59|\n",
            "|    max|             21.0|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "Read this https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html"
      ],
      "metadata": {
        "id": "KZ4pU5e0YRCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import LinearRegression library\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "#creating an object of class LinearRegression\n",
        "#object takes features and label as input arguments\n",
        "ship_lr=LinearRegression(featuresCol='features',labelCol='crew')\n",
        "#pass train_data to train model\n",
        "trained_ship_model=ship_lr.fit(train_data)                     # trained_ship_model, a TRAINED model, is a Transformer\n",
        "#evaluating model trained for Rsquared error\n",
        "ship_results=trained_ship_model.evaluate(train_data)\n",
        "\n",
        "print('Rsquared Error :',ship_results.r2)\n",
        "#R2 value shows accuracy of model is 92%\n",
        "#model accuracy is very good and can be use for predictive analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQzHX87nYd6-",
        "outputId": "32bc06ec-cb10-45f3-f497-6487b7fdfd4d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rsquared Error : 0.9203512683754324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "79KsT9AGZGVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Unlabelled Data"
      ],
      "metadata": {
        "id": "XCdxTnR6bUu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing Model on unlabeled data\n",
        "#create unlabeled data from test_data\n",
        "#testing model on unlabeled data\n",
        "unlabeled_data=test_data.select('features')\n",
        "unlabeled_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lue3EJ5ZIRF",
        "outputId": "9b3fffff-dbd6-4494-bf01-38737d385c26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[5.0,86.0,21.04,9...|\n",
            "|[6.0,110.23899999...|\n",
            "|[6.0,112.0,38.0,9...|\n",
            "|[6.0,158.0,43.7,1...|\n",
            "|[8.0,91.0,22.44,9...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trained_ship_model.transform(unlabeled_data)      # the Transformer, trained_ship_model, is transforming data, unlabelled_data\n",
        "predictions.show()\n",
        "#below are the results of output from test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN5eHyZjaowH",
        "outputId": "4c249e19-5f76-49b3-8787-7bcd76bcd201"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|        prediction|\n",
            "+--------------------+------------------+\n",
            "|[5.0,86.0,21.04,9...| 9.368365536226147|\n",
            "|[6.0,110.23899999...| 11.13261847891943|\n",
            "|[6.0,112.0,38.0,9...| 11.26745098661872|\n",
            "|[6.0,158.0,43.7,1...|13.930889444873722|\n",
            "|[8.0,91.0,22.44,9...|10.148806268182343|\n",
            "|[8.0,110.0,29.74,...|12.145215127373495|\n",
            "|[9.0,113.0,26.74,...|11.373910934326192|\n",
            "|[9.0,113.0,26.74,...|11.373910934326192|\n",
            "|[10.0,58.825,15.6...| 7.330934910647737|\n",
            "|[10.0,68.0,10.8,7...|  6.51915568961584|\n",
            "|[10.0,77.0,20.16,...| 8.774405845114932|\n",
            "|[10.0,86.0,21.14,...| 9.715167678100668|\n",
            "|[11.0,58.6,15.66,...| 7.450326582255584|\n",
            "|[11.0,90.09,25.01...| 8.942281278968554|\n",
            "|[11.0,138.0,31.14...|12.987070623258171|\n",
            "|[12.0,25.0,3.88,5...|3.0287651003744633|\n",
            "|[12.0,58.6,15.66,...| 7.434249560836164|\n",
            "|[12.0,90.09,25.01...| 8.921977608095387|\n",
            "|[13.0,61.0,13.8,7...| 6.561309774960774|\n",
            "|[13.0,63.0,14.4,7...| 6.748954511315354|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Labelled Data"
      ],
      "metadata": {
        "id": "8weWV82Fbbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted2 = trained_ship_model.transform(test_data)          # the Transformer, trained_ship_model, is transforming data, test_data\n",
        "predicted2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnzAeWx6a-gn",
        "outputId": "68415497-ec78-4893-833a-5297e15ee197"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|        prediction|\n",
            "+--------------------+-----+------------------+\n",
            "|[5.0,86.0,21.04,9...|  8.0| 9.368365536226147|\n",
            "|[6.0,110.23899999...| 11.5| 11.13261847891943|\n",
            "|[6.0,112.0,38.0,9...| 10.9| 11.26745098661872|\n",
            "|[6.0,158.0,43.7,1...| 13.6|13.930889444873722|\n",
            "|[8.0,91.0,22.44,9...| 11.0|10.148806268182343|\n",
            "|[8.0,110.0,29.74,...| 11.6|12.145215127373495|\n",
            "|[9.0,113.0,26.74,...|12.38|11.373910934326192|\n",
            "|[9.0,113.0,26.74,...|12.38|11.373910934326192|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.330934910647737|\n",
            "|[10.0,68.0,10.8,7...| 6.36|  6.51915568961584|\n",
            "|[10.0,77.0,20.16,...|  9.0| 8.774405845114932|\n",
            "|[10.0,86.0,21.14,...|  9.2| 9.715167678100668|\n",
            "|[11.0,58.6,15.66,...|  7.6| 7.450326582255584|\n",
            "|[11.0,90.09,25.01...| 8.48| 8.942281278968554|\n",
            "|[11.0,138.0,31.14...|11.85|12.987070623258171|\n",
            "|[12.0,25.0,3.88,5...| 2.87|3.0287651003744633|\n",
            "|[12.0,58.6,15.66,...|  7.0| 7.434249560836164|\n",
            "|[12.0,90.09,25.01...| 8.68| 8.921977608095387|\n",
            "|[13.0,61.0,13.8,7...|  6.0| 6.561309774960774|\n",
            "|[13.0,63.0,14.4,7...| 5.31| 6.748954511315354|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_ship_model.setPredictionCol(\"PraxisPredictions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUcIm5V0dErB",
        "outputId": "41d20675-d6a1-4acc-a382-acbd1c3a9107"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel: uid=LinearRegression_16fa7402d605, numFeatures=7"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted3 = trained_ship_model.transform(test_data)\n",
        "predicted3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNmdSX5dSOr",
        "outputId": "9cfa94c8-be8e-4f97-f06c-87a6e96f65f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|PraxisPredictions!|\n",
            "+--------------------+-----+------------------+\n",
            "|[5.0,86.0,21.04,9...|  8.0| 9.368365536226147|\n",
            "|[6.0,110.23899999...| 11.5| 11.13261847891943|\n",
            "|[6.0,112.0,38.0,9...| 10.9| 11.26745098661872|\n",
            "|[6.0,158.0,43.7,1...| 13.6|13.930889444873722|\n",
            "|[8.0,91.0,22.44,9...| 11.0|10.148806268182343|\n",
            "|[8.0,110.0,29.74,...| 11.6|12.145215127373495|\n",
            "|[9.0,113.0,26.74,...|12.38|11.373910934326192|\n",
            "|[9.0,113.0,26.74,...|12.38|11.373910934326192|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.330934910647737|\n",
            "|[10.0,68.0,10.8,7...| 6.36|  6.51915568961584|\n",
            "|[10.0,77.0,20.16,...|  9.0| 8.774405845114932|\n",
            "|[10.0,86.0,21.14,...|  9.2| 9.715167678100668|\n",
            "|[11.0,58.6,15.66,...|  7.6| 7.450326582255584|\n",
            "|[11.0,90.09,25.01...| 8.48| 8.942281278968554|\n",
            "|[11.0,138.0,31.14...|11.85|12.987070623258171|\n",
            "|[12.0,25.0,3.88,5...| 2.87|3.0287651003744633|\n",
            "|[12.0,58.6,15.66,...|  7.0| 7.434249560836164|\n",
            "|[12.0,90.09,25.01...| 8.68| 8.921977608095387|\n",
            "|[13.0,61.0,13.8,7...|  6.0| 6.561309774960774|\n",
            "|[13.0,63.0,14.4,7...| 5.31| 6.748954511315354|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "CBbIGsHfqQHN",
        "outputId": "1f815718-bc0d-402b-a19f-13cd0fffb379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2023-06-18 06:55:32.719506+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE1gjD5yNfrO"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself.\n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}