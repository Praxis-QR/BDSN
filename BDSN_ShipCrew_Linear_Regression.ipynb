{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDSN_ShipCrew Linear Regression",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/BDSN_ShipCrew_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSccZgVu7J8"
      },
      "source": [
        "![CC-BY-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)<br>\n",
        "<hr>\n",
        "\n",
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('Tested',datetime.now(pytz.timezone('Asia/Calcutta')))"
      ],
      "metadata": {
        "id": "yy2REumumhvw",
        "outputId": "3e954f20-502a-4c21-b3bb-01d12345f2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested 2023-06-19 11:29:16.587202+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-6MzHBr88H"
      },
      "source": [
        "# BDSN Ship Crews <br>\n",
        "https://www.geeksforgeeks.org/pyspark-linear-regression-using-apache-mllib/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqGXJ8DIxzWN"
      },
      "source": [
        "# Initialise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deprecated -- do not use"
      ],
      "metadata": {
        "id": "HICvwwOMsbcj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr826zIx3Kh"
      },
      "source": [
        "#!apt-get update > /dev/null\n",
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "#!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_l58UKyQ65"
      },
      "source": [
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Spark, current version"
      ],
      "metadata": {
        "id": "ZLTIcLnstJT_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3hdu86YyVEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "7212e348-7ae3-47c5-9876-d44e27d72770"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "!pip3 install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Praxis_Shipping').master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=Praxis_Shipping>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://aa2eb680f76f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Praxis_Shipping</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPnrUzlSsLN2"
      },
      "source": [
        "# Load Data <br>\n",
        "Data is available at https://drive.google.com/file/d/1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW476lcv5SGE"
      },
      "source": [
        "# Get Data\n",
        "#!gdown https://drive.google.com/uc?id=1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw\n",
        "!wget -q 'https://raw.githubusercontent.com/Praxis-QR/BDSN/main/data/ML/ShippingCrewInfo.csv'\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds4N6HfQszq7"
      },
      "source": [
        "#!ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_df=spark.read.csv('/content/ShippingCrewInfo.csv',inferSchema=True,header=True)\n",
        "crew_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3vO6Zq1Ue62",
        "outputId": "9ed451ef-f7b3-47b8-9a6a-6d9092ea5145"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints structure of dataframe along with datatype\n",
        "crew_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu2pMQ_CU4_X",
        "outputId": "802d0599-0f64-463d-b728-d56d7320d0a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Tonnage: double (nullable = true)\n",
            " |-- passengers: double (nullable = true)\n",
            " |-- length: double (nullable = true)\n",
            " |-- cabins: double (nullable = true)\n",
            " |-- passenger_density: double (nullable = true)\n",
            " |-- crew: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing : Indexing, Vectorising"
      ],
      "metadata": {
        "id": "5XmoRY_NWc4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns identified as features are as below:\n",
        "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
        "#to work on the features, spark MLlib expects every value to be in numeric form\n",
        "#feature 'Cruise_line is string datatype\n",
        "#using StringIndexer, string type will be typecast to numeric datatype\n",
        "#import library strinindexer for typecasting\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol='Cruise_line',outputCol='cruise_cat')\n",
        "crew_df2 = indexer.fit(crew_df).transform(crew_df)                        # indexer.fit(crew_df) is a Transformer\n",
        "\n",
        "#above code will convert string to numeric feature and create a new dataframe\n",
        "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
        "#feature cruise_cat is now vectorized and can be used to fed to model\n",
        "crew_df2.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQpXOeAXVMSX",
        "outputId": "a954d2ac-da44-4521-cba1-a6755478f9b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "#creating vectors from features\n",
        "#Apache MLlib takes input if vector form\n",
        "assembler=VectorAssembler(inputCols=['Age',\n",
        " 'Tonnage',\n",
        " 'passengers',\n",
        " 'length',\n",
        " 'cabins',\n",
        " 'passenger_density',\n",
        " 'cruise_cat'],outputCol='features')\n",
        "crew_df3=assembler.transform(crew_df2)                              # assember is a Transformer\n",
        "crew_df3.head(3)\n",
        "#crew_df3.select('features','crew').show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWK8Ww8sWx5j",
        "outputId": "48f900d4-48e7-4da5-dd19-091eb4972d2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0, features=DenseVector([26.0, 47.262, 14.86, 7.22, 7.43, 31.8, 1.0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final data consist of features and label which is crew.\n",
        "data=crew_df3.select('features','crew')\n",
        "#splitting data into train and test\n",
        "train_data,test_data=data.randomSplit([0.7,0.3])\n",
        "train_data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3PZN_AXukO",
        "outputId": "2eea0c24-01fd-4698-bada-f47404a586c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|             crew|\n",
            "+-------+-----------------+\n",
            "|  count|              106|\n",
            "|   mean|7.773396226415105|\n",
            "| stddev| 3.42411973722339|\n",
            "|    min|             0.59|\n",
            "|    max|             19.1|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "Read this https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html"
      ],
      "metadata": {
        "id": "KZ4pU5e0YRCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import LinearRegression library\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "#creating an object of class LinearRegression\n",
        "#object takes features and label as input arguments\n",
        "ship_lr=LinearRegression(featuresCol='features',labelCol='crew')\n",
        "#pass train_data to train model\n",
        "trained_ship_model=ship_lr.fit(train_data)                     # trained_ship_model, a TRAINED model, is a Transformer\n",
        "#evaluating model trained for Rsquared error\n",
        "ship_results=trained_ship_model.evaluate(train_data)\n",
        "\n",
        "print('Rsquared Error :',ship_results.r2)\n",
        "#R2 value shows accuracy of model is 92%\n",
        "#model accuracy is very good and can be use for predictive analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQzHX87nYd6-",
        "outputId": "2a44b26f-e6f9-4c00-fc22-1a3fa7d75bd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rsquared Error : 0.9200424003270061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "79KsT9AGZGVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Unlabelled Data"
      ],
      "metadata": {
        "id": "XCdxTnR6bUu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing Model on unlabeled data\n",
        "#create unlabeled data from test_data\n",
        "#testing model on unlabeled data\n",
        "unlabeled_data=test_data.select('features')\n",
        "unlabeled_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lue3EJ5ZIRF",
        "outputId": "278cb078-261e-4497-b384-b86f26a1997f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[4.0,220.0,54.0,1...|\n",
            "|[5.0,115.0,35.74,...|\n",
            "|[5.0,133.5,39.59,...|\n",
            "|[6.0,30.276999999...|\n",
            "|[6.0,93.0,23.94,9...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trained_ship_model.transform(unlabeled_data)      # the Transformer, trained_ship_model, is transforming data, unlabelled_data\n",
        "predictions.show()\n",
        "#below are the results of output from test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN5eHyZjaowH",
        "outputId": "967f8c6f-81c4-4611-e2b3-810bfbf84393"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|        prediction|\n",
            "+--------------------+------------------+\n",
            "|[4.0,220.0,54.0,1...|20.619841496320667|\n",
            "|[5.0,115.0,35.74,...|11.903270041797795|\n",
            "|[5.0,133.5,39.59,...|13.235465958102614|\n",
            "|[6.0,30.276999999...| 4.474192495161946|\n",
            "|[6.0,93.0,23.94,9...|10.752309235147557|\n",
            "|[7.0,89.6,25.5,9....| 11.34350339830189|\n",
            "|[8.0,110.0,29.74,...|12.190697877821636|\n",
            "|[9.0,110.0,29.74,...|12.177156022836641|\n",
            "|[9.0,113.0,26.74,...|11.338229047910275|\n",
            "|[10.0,46.0,7.0,6....|2.7312742495094398|\n",
            "|[10.0,58.825,15.6...| 7.507259079215254|\n",
            "|[10.0,81.76899999...|   8.9518555465398|\n",
            "|[10.0,105.0,27.2,...|11.268371412490557|\n",
            "|[11.0,85.0,18.48,...| 8.883254660153254|\n",
            "|[11.0,90.09,25.01...| 9.002894444829078|\n",
            "|[11.0,91.62700000...| 9.271573302595128|\n",
            "|[12.0,25.0,3.88,5...| 2.878115467906081|\n",
            "|[12.0,58.6,15.66,...| 7.624571638442161|\n",
            "|[12.0,108.865,27....|10.846714549460458|\n",
            "|[12.0,138.0,31.14...|12.844398213494252|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Labelled Data"
      ],
      "metadata": {
        "id": "8weWV82Fbbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted2 = trained_ship_model.transform(test_data)          # the Transformer, trained_ship_model, is transforming data, test_data\n",
        "predicted2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnzAeWx6a-gn",
        "outputId": "f759d669-8421-4447-d3dc-f94540d127a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|        prediction|\n",
            "+--------------------+-----+------------------+\n",
            "|[4.0,220.0,54.0,1...| 21.0|20.619841496320667|\n",
            "|[5.0,115.0,35.74,...| 12.2|11.903270041797795|\n",
            "|[5.0,133.5,39.59,...|13.13|13.235465958102614|\n",
            "|[6.0,30.276999999...| 3.55| 4.474192495161946|\n",
            "|[6.0,93.0,23.94,9...|11.09|10.752309235147557|\n",
            "|[7.0,89.6,25.5,9....| 9.87| 11.34350339830189|\n",
            "|[8.0,110.0,29.74,...| 11.6|12.190697877821636|\n",
            "|[9.0,110.0,29.74,...| 11.6|12.177156022836641|\n",
            "|[9.0,113.0,26.74,...|12.38|11.338229047910275|\n",
            "|[10.0,46.0,7.0,6....| 4.47|2.7312742495094398|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.507259079215254|\n",
            "|[10.0,81.76899999...| 8.42|   8.9518555465398|\n",
            "|[10.0,105.0,27.2,...|10.68|11.268371412490557|\n",
            "|[11.0,85.0,18.48,...|  8.0| 8.883254660153254|\n",
            "|[11.0,90.09,25.01...| 8.48| 9.002894444829078|\n",
            "|[11.0,91.62700000...|  9.0| 9.271573302595128|\n",
            "|[12.0,25.0,3.88,5...| 2.87| 2.878115467906081|\n",
            "|[12.0,58.6,15.66,...|  7.0| 7.624571638442161|\n",
            "|[12.0,108.865,27....| 11.0|10.846714549460458|\n",
            "|[12.0,138.0,31.14...|11.85|12.844398213494252|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_ship_model.setPredictionCol(\"PraxisPredictions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUcIm5V0dErB",
        "outputId": "1eb99741-df22-4936-bf36-1e572dbe4e98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel: uid=LinearRegression_5d97b29c6c67, numFeatures=7"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted3 = trained_ship_model.transform(test_data)\n",
        "predicted3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNmdSX5dSOr",
        "outputId": "efdb76d6-4ad1-4231-ebf0-59ff562284a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------------+\n",
            "|            features| crew|PraxisPredictions!|\n",
            "+--------------------+-----+------------------+\n",
            "|[4.0,220.0,54.0,1...| 21.0|20.619841496320667|\n",
            "|[5.0,115.0,35.74,...| 12.2|11.903270041797795|\n",
            "|[5.0,133.5,39.59,...|13.13|13.235465958102614|\n",
            "|[6.0,30.276999999...| 3.55| 4.474192495161946|\n",
            "|[6.0,93.0,23.94,9...|11.09|10.752309235147557|\n",
            "|[7.0,89.6,25.5,9....| 9.87| 11.34350339830189|\n",
            "|[8.0,110.0,29.74,...| 11.6|12.190697877821636|\n",
            "|[9.0,110.0,29.74,...| 11.6|12.177156022836641|\n",
            "|[9.0,113.0,26.74,...|12.38|11.338229047910275|\n",
            "|[10.0,46.0,7.0,6....| 4.47|2.7312742495094398|\n",
            "|[10.0,58.825,15.6...|  7.0| 7.507259079215254|\n",
            "|[10.0,81.76899999...| 8.42|   8.9518555465398|\n",
            "|[10.0,105.0,27.2,...|10.68|11.268371412490557|\n",
            "|[11.0,85.0,18.48,...|  8.0| 8.883254660153254|\n",
            "|[11.0,90.09,25.01...| 8.48| 9.002894444829078|\n",
            "|[11.0,91.62700000...|  9.0| 9.271573302595128|\n",
            "|[12.0,25.0,3.88,5...| 2.87| 2.878115467906081|\n",
            "|[12.0,58.6,15.66,...|  7.0| 7.624571638442161|\n",
            "|[12.0,108.865,27....| 11.0|10.846714549460458|\n",
            "|[12.0,138.0,31.14...|11.85|12.844398213494252|\n",
            "+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "CBbIGsHfqQHN",
        "outputId": "6ac002f3-2062-4c99-faa4-ad2cc47eb113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2023-06-19 11:35:43.610795+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE1gjD5yNfrO"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself.\n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}