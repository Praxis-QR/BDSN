{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDSN_ShipCrew Linear Regression",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/BDSN_ShipCrew_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSccZgVu7J8"
      },
      "source": [
        "![CC-BY-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)<br>\n",
        "<hr>\n",
        "\n",
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('Tested',datetime.now(pytz.timezone('Asia/Calcutta')))"
      ],
      "metadata": {
        "id": "yy2REumumhvw",
        "outputId": "79c61b52-6e8b-4c34-b1b0-58ef5a581676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested 2024-06-12 07:23:10.084126+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-6MzHBr88H"
      },
      "source": [
        "# BDSN Ship Crews <br>\n",
        "https://www.geeksforgeeks.org/pyspark-linear-regression-using-apache-mllib/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqGXJ8DIxzWN"
      },
      "source": [
        "# Initialise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deprecated -- do not use"
      ],
      "metadata": {
        "id": "HICvwwOMsbcj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr826zIx3Kh"
      },
      "source": [
        "#!apt-get update > /dev/null\n",
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "#!pip install -q pyspark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_l58UKyQ65"
      },
      "source": [
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Spark, current version"
      ],
      "metadata": {
        "id": "ZLTIcLnstJT_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3hdu86YyVEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "bff7f519-d979-4c97-c4b4-3e26b6682f26"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "!pip3 install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Praxis_Shipping').master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=Praxis_Shipping>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ef943e177859:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Praxis_Shipping</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPnrUzlSsLN2"
      },
      "source": [
        "# Load Data <br>\n",
        "Data is available at https://drive.google.com/file/d/1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW476lcv5SGE"
      },
      "source": [
        "# Get Data\n",
        "#!gdown https://drive.google.com/uc?id=1fLGDQjsnA3RzTzzEVDpHxyy5ERzcV9Qw\n",
        "!wget -q 'https://raw.githubusercontent.com/Praxis-QR/BDSN/main/data/ML/ShippingCrewInfo.csv'\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds4N6HfQszq7"
      },
      "source": [
        "#!ls -al"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_df=spark.read.csv('/content/ShippingCrewInfo.csv',inferSchema=True,header=True)\n",
        "crew_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3vO6Zq1Ue62",
        "outputId": "0c9c6c1c-d19f-414f-bc3d-e67ffbdb5519"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints structure of dataframe along with datatype\n",
        "crew_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu2pMQ_CU4_X",
        "outputId": "2e98d725-2ad8-4b84-fd02-caf9735fb312"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Tonnage: double (nullable = true)\n",
            " |-- passengers: double (nullable = true)\n",
            " |-- length: double (nullable = true)\n",
            " |-- cabins: double (nullable = true)\n",
            " |-- passenger_density: double (nullable = true)\n",
            " |-- crew: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing : Indexing, Vectorising"
      ],
      "metadata": {
        "id": "5XmoRY_NWc4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns identified as features are as below:\n",
        "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
        "#to work on the features, spark MLlib expects every value to be in numeric form\n",
        "#feature 'Cruise_line is string datatype\n",
        "#using StringIndexer, string type will be typecast to numeric datatype\n",
        "#import library strinindexer for typecasting\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol='Cruise_line',outputCol='cruise_cat')\n",
        "crew_df2 = indexer.fit(crew_df).transform(crew_df)                        # indexer.fit(crew_df) is a Transformer\n",
        "\n",
        "#above code will convert string to numeric feature and create a new dataframe\n",
        "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
        "#feature cruise_cat is now vectorized and can be used to fed to model\n",
        "crew_df2.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQpXOeAXVMSX",
        "outputId": "625a0854-e7ed-4038-dcb5-c817b97f5f93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "#creating vectors from features\n",
        "#Apache MLlib takes input if vector form\n",
        "assembler=VectorAssembler(inputCols=['Age',\n",
        " 'Tonnage',\n",
        " 'passengers',\n",
        " 'length',\n",
        " 'cabins',\n",
        " 'passenger_density',\n",
        " 'cruise_cat'],outputCol='features')\n",
        "crew_df3=assembler.transform(crew_df2)                              # assember is a Transformer\n",
        "crew_df3.head(3)\n",
        "#crew_df3.select('features','crew').show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWK8Ww8sWx5j",
        "outputId": "7d967392-66ed-40af-c873-05b2960be238"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0, features=DenseVector([6.0, 30.277, 6.94, 5.94, 3.55, 42.64, 16.0])),\n",
              " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0, features=DenseVector([26.0, 47.262, 14.86, 7.22, 7.43, 31.8, 1.0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final data consist of features and label which is crew.\n",
        "data=crew_df3.select('features','crew')\n",
        "#splitting data into train and test\n",
        "train_data,test_data=data.randomSplit([0.7,0.3])\n",
        "train_data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3PZN_AXukO",
        "outputId": "36f399db-958b-4a7d-afb5-39bf37bddbf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|             crew|\n",
            "+-------+-----------------+\n",
            "|  count|              105|\n",
            "|   mean|7.856285714285724|\n",
            "| stddev|3.561505531141522|\n",
            "|    min|             0.59|\n",
            "|    max|             21.0|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "Read this https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html"
      ],
      "metadata": {
        "id": "KZ4pU5e0YRCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import LinearRegression library\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "#creating an object of class LinearRegression\n",
        "#object takes features and label as input arguments\n",
        "ship_lr=LinearRegression(featuresCol='features',labelCol='crew')\n",
        "#pass train_data to train model\n",
        "trained_ship_model=ship_lr.fit(train_data)                     # trained_ship_model, a TRAINED model, is a Transformer\n",
        "#evaluating model trained for Rsquared error\n",
        "ship_results=trained_ship_model.evaluate(train_data)\n",
        "\n",
        "print('Rsquared Error :',ship_results.r2)\n",
        "#R2 value shows accuracy of model is 92%\n",
        "#model accuracy is very good and can be use for predictive analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQzHX87nYd6-",
        "outputId": "4ed7c145-a52f-45d4-f3bc-21fbe01bd0f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rsquared Error : 0.9121612305972863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "79KsT9AGZGVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Unlabelled Data"
      ],
      "metadata": {
        "id": "XCdxTnR6bUu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing Model on unlabeled data\n",
        "#create unlabeled data from test_data\n",
        "#testing model on unlabeled data\n",
        "unlabeled_data=test_data.select('features')\n",
        "unlabeled_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lue3EJ5ZIRF",
        "outputId": "1167f556-8c26-433d-c785-21ea3d941a24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[5.0,122.0,28.5,1...|\n",
            "|[5.0,133.5,39.59,...|\n",
            "|[6.0,30.276999999...|\n",
            "|[6.0,110.23899999...|\n",
            "|[6.0,113.0,37.82,...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=trained_ship_model.transform(unlabeled_data)      # the Transformer, trained_ship_model, is transforming data, unlabelled_data\n",
        "predictions.show()\n",
        "#below are the results of output from test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN5eHyZjaowH",
        "outputId": "b24a0e21-ef89-4199-db3f-82b1f4a8d716"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+\n",
            "|            features|         prediction|\n",
            "+--------------------+-------------------+\n",
            "|[5.0,122.0,28.5,1...|    4.1719028802411|\n",
            "|[5.0,133.5,39.59,...| 13.026416885391516|\n",
            "|[6.0,30.276999999...|  4.345076560473145|\n",
            "|[6.0,110.23899999...| 11.275475266809107|\n",
            "|[6.0,113.0,37.82,...| 11.913557294975233|\n",
            "|[6.0,158.0,43.7,1...| 13.535963288975148|\n",
            "|[8.0,110.0,29.74,...| 12.435236877394626|\n",
            "|[9.0,81.0,21.44,9...|  9.718857633521138|\n",
            "|[9.0,85.0,19.68,9...|  9.275849392342883|\n",
            "|[9.0,90.09,25.01,...|  9.204575395129206|\n",
            "|[9.0,105.0,27.2,8...| 11.415377315231504|\n",
            "|[9.0,110.0,29.74,...|  12.42423514715553|\n",
            "|[9.0,113.0,26.74,...|   11.2942175847381|\n",
            "|[10.0,68.0,10.8,7...|  6.342748416999593|\n",
            "|[10.0,91.62700000...|  9.049694026053789|\n",
            "|[10.0,151.4,26.2,...|  9.854906004074692|\n",
            "|[11.0,90.0,22.4,9...| 10.118134883696662|\n",
            "|[12.0,2.329,0.94,...|0.22206727816010408|\n",
            "|[12.0,42.0,14.8,7...|  6.987205517055531|\n",
            "|[12.0,88.5,21.24,...|  9.481510248672446|\n",
            "+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Labelled Data"
      ],
      "metadata": {
        "id": "8weWV82Fbbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted2 = trained_ship_model.transform(test_data)          # the Transformer, trained_ship_model, is transforming data, test_data\n",
        "predicted2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnzAeWx6a-gn",
        "outputId": "be87b833-3592-48c7-9232-b8410b80d51e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------------------+\n",
            "|            features| crew|         prediction|\n",
            "+--------------------+-----+-------------------+\n",
            "|[5.0,122.0,28.5,1...|  6.7|    4.1719028802411|\n",
            "|[5.0,133.5,39.59,...|13.13| 13.026416885391516|\n",
            "|[6.0,30.276999999...| 3.55|  4.345076560473145|\n",
            "|[6.0,110.23899999...| 11.5| 11.275475266809107|\n",
            "|[6.0,113.0,37.82,...| 12.0| 11.913557294975233|\n",
            "|[6.0,158.0,43.7,1...| 13.6| 13.535963288975148|\n",
            "|[8.0,110.0,29.74,...| 11.6| 12.435236877394626|\n",
            "|[9.0,81.0,21.44,9...| 10.0|  9.718857633521138|\n",
            "|[9.0,85.0,19.68,9...| 8.69|  9.275849392342883|\n",
            "|[9.0,90.09,25.01,...| 8.69|  9.204575395129206|\n",
            "|[9.0,105.0,27.2,8...|10.68| 11.415377315231504|\n",
            "|[9.0,110.0,29.74,...| 11.6|  12.42423514715553|\n",
            "|[9.0,113.0,26.74,...|12.38|   11.2942175847381|\n",
            "|[10.0,68.0,10.8,7...| 6.36|  6.342748416999593|\n",
            "|[10.0,91.62700000...|  9.0|  9.049694026053789|\n",
            "|[10.0,151.4,26.2,...|12.53|  9.854906004074692|\n",
            "|[11.0,90.0,22.4,9...| 11.0| 10.118134883696662|\n",
            "|[12.0,2.329,0.94,...|  0.6|0.22206727816010408|\n",
            "|[12.0,42.0,14.8,7...|  6.8|  6.987205517055531|\n",
            "|[12.0,88.5,21.24,...|10.29|  9.481510248672446|\n",
            "+--------------------+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_ship_model.setPredictionCol(\"PraxisPredictions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUcIm5V0dErB",
        "outputId": "9db33042-9b54-4fbc-e6cc-0b0368955fb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel: uid=LinearRegression_31619dff5b02, numFeatures=7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted3 = trained_ship_model.transform(test_data)\n",
        "predicted3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNmdSX5dSOr",
        "outputId": "bc941979-85b2-4492-acdb-54d640472996"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------------------+\n",
            "|            features| crew| PraxisPredictions!|\n",
            "+--------------------+-----+-------------------+\n",
            "|[5.0,122.0,28.5,1...|  6.7|    4.1719028802411|\n",
            "|[5.0,133.5,39.59,...|13.13| 13.026416885391516|\n",
            "|[6.0,30.276999999...| 3.55|  4.345076560473145|\n",
            "|[6.0,110.23899999...| 11.5| 11.275475266809107|\n",
            "|[6.0,113.0,37.82,...| 12.0| 11.913557294975233|\n",
            "|[6.0,158.0,43.7,1...| 13.6| 13.535963288975148|\n",
            "|[8.0,110.0,29.74,...| 11.6| 12.435236877394626|\n",
            "|[9.0,81.0,21.44,9...| 10.0|  9.718857633521138|\n",
            "|[9.0,85.0,19.68,9...| 8.69|  9.275849392342883|\n",
            "|[9.0,90.09,25.01,...| 8.69|  9.204575395129206|\n",
            "|[9.0,105.0,27.2,8...|10.68| 11.415377315231504|\n",
            "|[9.0,110.0,29.74,...| 11.6|  12.42423514715553|\n",
            "|[9.0,113.0,26.74,...|12.38|   11.2942175847381|\n",
            "|[10.0,68.0,10.8,7...| 6.36|  6.342748416999593|\n",
            "|[10.0,91.62700000...|  9.0|  9.049694026053789|\n",
            "|[10.0,151.4,26.2,...|12.53|  9.854906004074692|\n",
            "|[11.0,90.0,22.4,9...| 11.0| 10.118134883696662|\n",
            "|[12.0,2.329,0.94,...|  0.6|0.22206727816010408|\n",
            "|[12.0,42.0,14.8,7...|  6.8|  6.987205517055531|\n",
            "|[12.0,88.5,21.24,...|10.29|  9.481510248672446|\n",
            "+--------------------+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "CBbIGsHfqQHN",
        "outputId": "39fe2324-2f90-48d5-b922-f2f9d74bc08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2024-06-12 07:24:37.668734+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE1gjD5yNfrO"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself.\n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}