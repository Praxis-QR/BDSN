{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDS-DailyShow",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/BDSN_DailyShow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkrz1wMFvnb_"
      },
      "source": [
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oq35CX7KTRf"
      },
      "source": [
        "Apache Spark: An Introduction\n",
        "https://www.dataquest.io/blog/apache-spark/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Data"
      ],
      "metadata": {
        "id": "j6XqTemht8Jm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBpu9hgTqJMk"
      },
      "source": [
        "#import urllib.request\n",
        "#urllib.request.urlretrieve('https://raw.githubusercontent.com/fivethirtyeight/data/master/daily-show-guests/daily_show_guests.csv','dsg.csv')\n",
        "#!wget 'https://raw.githubusercontent.com/fivethirtyeight/data/master/daily-show-guests/daily_show_guests.csv'\n",
        "#!gdown https://drive.google.com/uc?id=1UQWzVXAg2ytuAmtizEsWx6E1D38XUBX4\n",
        "!wget -q  'https://raw.githubusercontent.com/Praxis-QR/BDSN/main/data/dailyshow/daily_show_guests.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlUPgXwhNAi6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This approach is not required anymore -- deprecated"
      ],
      "metadata": {
        "id": "7Mq-fy7Q9tpa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISo88MdIjSE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeb9790-6f06-4c23-a99d-031bcdd46c9d"
      },
      "source": [
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 39 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.8 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDRK6_rijFl3"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Direct PIP Approach "
      ],
      "metadata": {
        "id": "wXT3w_Sx90-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 -q install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK-kbkHu9-Kn",
        "outputId": "2afef73c-304d-40a3-bc9a-2684ff8b1651"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQPAU53MLruJ"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "#from pyspark.sql import SparkSession\n",
        "#spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# note UI port switched from default 4040 to 4050 to avoid clash with ngrok\n",
        "#spark = SparkSession.builder.master(\"local[*]\").config('spark.ui.port', '4050').getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VOhVTZeLyx7",
        "outputId": "cde2b30b-f81c-46a6-882b-caffaf3c2c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c0e47c399fcc:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJTLrfSML1lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a09c7c-37fa-4b40-bd6e-43423f324bc4"
      },
      "source": [
        "raw_data = sc.textFile(\"daily_show_guests.csv\")\n",
        "raw_data.take(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['YEAR,GoogleKnowlege_Occupation,Show,Group,Raw_Guest_List',\n",
              " '1999,actor,1/11/99,Acting,Michael J. Fox',\n",
              " '1999,Comedian,1/12/99,Comedy,Sandra Bernhard',\n",
              " '1999,television actress,1/13/99,Acting,Tracey Ullman',\n",
              " '1999,film actress,1/14/99,Acting,Gillian Anderson']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NAKnX_9NJnC"
      },
      "source": [
        "# Daily Show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI8xnT_XUCuV",
        "outputId": "d5ae73d0-145e-4ea5-f8a5-e9b7ef3d6bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# non Pythonic, non Spark of doing things\n",
        "#\n",
        "import csv\n",
        "\n",
        "f = open('daily_show_guests.csv')\n",
        "tally_D = dict()\n",
        "for line in f:\n",
        "    data_line = line.split(',')\n",
        "    year = data_line[0]\n",
        "    if year in tally_D.keys():\n",
        "       tally_D[year] = tally_D[year] + 1\n",
        "    else:\n",
        "       tally_D[year] = 1\n",
        "\n",
        "print(tally_D)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'YEAR': 1, '1999': 166, '2000': 169, '2001': 157, '2002': 159, '2003': 166, '2004': 164, '2005': 162, '2006': 161, '2007': 141, '2008': 164, '2009': 163, '2010': 165, '2011': 163, '2012': 164, '2013': 166, '2014': 163, '2015': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Spark"
      ],
      "metadata": {
        "id": "gS37fAsGuB8P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZuICvffNVDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e4174d-2cfe-4c82-8718-f1621ffcb630"
      },
      "source": [
        "daily_show = raw_data.map(lambda line: line.split(','))\n",
        "daily_show.take(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['YEAR', 'GoogleKnowlege_Occupation', 'Show', 'Group', 'Raw_Guest_List'],\n",
              " ['1999', 'actor', '1/11/99', 'Acting', 'Michael J. Fox'],\n",
              " ['1999', 'Comedian', '1/12/99', 'Comedy', 'Sandra Bernhard'],\n",
              " ['1999', 'television actress', '1/13/99', 'Acting', 'Tracey Ullman'],\n",
              " ['1999', 'film actress', '1/14/99', 'Acting', 'Gillian Anderson']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ViRYoAyMiMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea36a51-41c9-461c-bb56-b50ac4e97fd2"
      },
      "source": [
        "tallyMap = daily_show.map(lambda x: (x[0], 1))\n",
        "tallyMap.take(5)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('YEAR', 1), ('1999', 1), ('1999', 1), ('1999', 1), ('1999', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4kpBE3VNbT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee093529-d00f-4b79-8010-57a57860236d"
      },
      "source": [
        "tallyRed = tallyMap.reduceByKey(lambda x,y: x+y)\n",
        "tallyRed.take(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('YEAR', 1), ('2002', 159), ('2003', 166), ('2004', 164), ('2007', 141)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRgW0JoSOISo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8777bbaf-c24a-4131-b61b-dba9dace8159"
      },
      "source": [
        "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
        "print(tally)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PythonRDD[14] at RDD at PythonRDD.scala:53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YTnfPs4duuS",
        "outputId": "68cf4c48-bdb4-4d4d-819d-8b478b118edd"
      },
      "source": [
        "tally.count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8teWmXNOS4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1eee6ef-e718-494b-b9a8-906093a160aa"
      },
      "source": [
        "tally.take(tally.count())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('YEAR', 1),\n",
              " ('2002', 159),\n",
              " ('2003', 166),\n",
              " ('2004', 164),\n",
              " ('2007', 141),\n",
              " ('2010', 165),\n",
              " ('2011', 163),\n",
              " ('2012', 164),\n",
              " ('2013', 166),\n",
              " ('2014', 163),\n",
              " ('2015', 100),\n",
              " ('1999', 166),\n",
              " ('2000', 169),\n",
              " ('2001', 157),\n",
              " ('2005', 162),\n",
              " ('2006', 161),\n",
              " ('2008', 164),\n",
              " ('2009', 163)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGiSNZfqPrgt"
      },
      "source": [
        "def filter_year(line):\n",
        "    if line[0] == 'YEAR':\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "filtered_daily_show = daily_show.filter(lambda line: filter_year(line))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8pkylxVP7DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06149a7d-f46f-4ac8-8a2c-00b2b9d09f18"
      },
      "source": [
        "tally2 = filtered_daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
        "print(tally2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PythonRDD[23] at RDD at PythonRDD.scala:53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnq4co6iQFFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69b35e6-723b-4bc9-9943-6d23d9d76bf3"
      },
      "source": [
        "tally2.take(tally2.count())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2002', 159),\n",
              " ('2003', 166),\n",
              " ('2004', 164),\n",
              " ('2007', 141),\n",
              " ('2010', 165),\n",
              " ('2011', 163),\n",
              " ('2012', 164),\n",
              " ('2013', 166),\n",
              " ('2014', 163),\n",
              " ('2015', 100),\n",
              " ('1999', 166),\n",
              " ('2000', 169),\n",
              " ('2001', 157),\n",
              " ('2005', 162),\n",
              " ('2006', 161),\n",
              " ('2008', 164),\n",
              " ('2009', 163)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAepMpRvQVtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e78760-f9ac-43f9-edd7-7577675953e4"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .take(20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('film actress', 21),\n",
              " ('model', 9),\n",
              " ('stand-up comedian', 44),\n",
              " ('actress', 271),\n",
              " ('television personality', 13),\n",
              " ('comic', 2),\n",
              " ('musician', 19),\n",
              " ('film actor', 19),\n",
              " ('journalist', 253),\n",
              " ('us senator', 50),\n",
              " ('vocalist', 2),\n",
              " ('film director', 24),\n",
              " ('singer', 23),\n",
              " ('muppet', 2),\n",
              " ('american television personality', 3),\n",
              " ('rapper', 10),\n",
              " ('football player', 1),\n",
              " ('former mayor of cincinatti', 2),\n",
              " ('businesswoman', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v9s3gDsVX0q"
      },
      "source": [
        "## Extra Sorting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--xXTk9vhnei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e7d487-c0fd-4fd5-f85f-e8fd5e49748a"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .take(20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('film actress', 21),\n",
              " ('model', 9),\n",
              " ('stand-up comedian', 44),\n",
              " ('actress', 271),\n",
              " ('television personality', 13),\n",
              " ('comic', 2),\n",
              " ('musician', 19),\n",
              " ('film actor', 19),\n",
              " ('journalist', 253),\n",
              " ('us senator', 50),\n",
              " ('vocalist', 2),\n",
              " ('film director', 24),\n",
              " ('singer', 23),\n",
              " ('muppet', 2),\n",
              " ('american television personality', 3),\n",
              " ('rapper', 10),\n",
              " ('football player', 1),\n",
              " ('former mayor of cincinatti', 2),\n",
              " ('businesswoman', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDJhWpfh6wy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441f6a7f-af26-4446-e21a-e9c3926b41d3"
      },
      "source": [
        "#sorted by profession \n",
        "#not sorted by number of appearances\n",
        "# in sortbykey, 1st parameter determines direction of sort, second parameter is optional)\n",
        "# in sortbykey, 2nd parameter determines number of partition in output RDD\n",
        "# see next two cells\n",
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .sortByKey(0, 1) \\\n",
        "                   .take(20)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('writer', 52),\n",
              " ('white house sommunications director', 5),\n",
              " ('white house official', 1),\n",
              " ('vocalist', 2),\n",
              " ('vice president', 2),\n",
              " ('us senator', 50),\n",
              " ('us secretary of energy', 1),\n",
              " ('us secretary of defense', 1),\n",
              " ('us secetary of education', 1),\n",
              " ('us representative', 9),\n",
              " ('us president', 10),\n",
              " ('us permanent representative to nato', 1),\n",
              " ('us official', 1),\n",
              " ('us assistant attorney', 1),\n",
              " ('university professor', 2),\n",
              " ('united states senator', 15),\n",
              " ('united states senate member', 4),\n",
              " ('united states secretary of the navy', 1),\n",
              " ('united states secretary of housing and urban development', 1),\n",
              " ('united states secretary of defense', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKV1b5ejaCZ",
        "outputId": "463a4176-eded-424c-e4da-997220ff6ce7"
      },
      "source": [
        "#sorted by profession \n",
        "#not sorted by number of appearances\n",
        "# in sortbykey, 1st parameter determines direction of sort, second parameter is optional)\n",
        "# in sortbykey, 2nd parameter determines number of partition in output RDD\n",
        "# see next two cells\n",
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .sortByKey(1, 1) \\\n",
        "                   .take(20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('-', 1),\n",
              " ('0', 4),\n",
              " ('academic', 6),\n",
              " ('accountant', 1),\n",
              " ('activist', 14),\n",
              " ('actor', 596),\n",
              " ('actress', 271),\n",
              " ('administrator', 1),\n",
              " ('admiral', 2),\n",
              " ('adviser', 4),\n",
              " ('advocate', 1),\n",
              " ('aei president', 1),\n",
              " ('afghan politician', 1),\n",
              " ('american football quarterback', 3),\n",
              " ('american football running back', 1),\n",
              " ('american football wide receiver', 2),\n",
              " ('american football wide reciever', 1),\n",
              " ('american political figure', 2),\n",
              " ('american politician', 8),\n",
              " ('american television personality', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZl2duauLIV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd8a121-7a73-40b0-fdfa-bcc3597510dc"
      },
      "source": [
        "!rm -r dumpDir\n",
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .sortByKey(0,2)\\\n",
        "                   .saveAsTextFile(\"dumpDir\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'dumpDir': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkzLto2UlDk2",
        "outputId": "aec6f827-8cc9-41bc-b258-7a5359aa6e43"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .take(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('film actress', 21),\n",
              " ('model', 9),\n",
              " ('stand-up comedian', 44),\n",
              " ('actress', 271),\n",
              " ('television personality', 13),\n",
              " ('comic', 2),\n",
              " ('musician', 19),\n",
              " ('film actor', 19),\n",
              " ('journalist', 253)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25HW89np4WeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c662a92d-5cff-445c-cd1a-c8da98344319"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .map(lambda x: (x[1],x[0]))\\\n",
        "                   .take(10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(596, 'actor'),\n",
              " (21, 'film actress'),\n",
              " (9, 'model'),\n",
              " (44, 'stand-up comedian'),\n",
              " (271, 'actress'),\n",
              " (13, 'television personality'),\n",
              " (2, 'comic'),\n",
              " (19, 'musician'),\n",
              " (19, 'film actor'),\n",
              " (253, 'journalist')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WQK_2IGLAHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3349afa2-df8e-475e-c4ac-2750d63b9984"
      },
      "source": [
        "#to sort by number of appearances, we first need to flip the key and value \n",
        "#\n",
        "\n",
        "# sort 1st arg configures ascending sort, 2nd configures 1 task\n",
        "# https://stackoverflow.com/questions/38569052/how-do-i-invert-key-and-value-in-rdd-in-python-3-pyspark\n",
        "\n",
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .map(lambda x: (x[1],x[0]))\\\n",
        "                   .sortByKey(0, 1) \\\n",
        "                   .map(lambda x: (x[1],x[0])) \\\n",
        "                   .take(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('actress', 271),\n",
              " ('journalist', 253),\n",
              " ('author', 152),\n",
              " ('comedian', 103),\n",
              " ('writer', 52),\n",
              " ('us senator', 50),\n",
              " ('stand-up comedian', 44),\n",
              " ('television host', 39),\n",
              " ('professor', 37)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6wvD6xX8LX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33099ae0-9b07-4cd7-d150-e671105f902d"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .sortBy(lambda x : -1*x[1])\\\n",
        "                   .take(10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('actress', 271),\n",
              " ('journalist', 253),\n",
              " ('author', 152),\n",
              " ('comedian', 103),\n",
              " ('writer', 52),\n",
              " ('us senator', 50),\n",
              " ('stand-up comedian', 44),\n",
              " ('television host', 39),\n",
              " ('professor', 37)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PNZ2615Q3LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e1f45a-00c4-40d5-dbbf-a77e0c48019d"
      },
      "source": [
        "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
        "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
        "                   .reduceByKey(lambda x,y: x+y) \\\n",
        "                   .takeOrdered(10, lambda aTuple:-1*aTuple[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actor', 596),\n",
              " ('actress', 271),\n",
              " ('journalist', 253),\n",
              " ('author', 152),\n",
              " ('comedian', 103),\n",
              " ('writer', 52),\n",
              " ('us senator', 50),\n",
              " ('stand-up comedian', 44),\n",
              " ('television host', 39),\n",
              " ('professor', 37)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM4xcb4fXSdF",
        "outputId": "3e5d9a1f-16f1-43df-d050-450ec9bf69c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2023-04-03 11:36:59.920688+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBwtjLY2hJFk"
      },
      "source": [
        "#Chronobooks <br>\n",
        "Two science fiction novels by Prithwis Mukerjee. A dystopian Earth. A technocratic society managed by artificial intelligence. Escape and epiphany on Mars. Can man and machine, carbon and silicon explore and escape into other dimensions of existence? An Indic perspective rooted in Advaita Vedanta and the Divine Feminine.  [More information](http://bit.ly/chronobooks) <br>\n",
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/CTCYFooter-1.png)"
      ]
    }
  ]
}