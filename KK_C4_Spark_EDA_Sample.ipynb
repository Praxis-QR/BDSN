{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W2QOKe1NRHn4",
        "sRvq6-Cd5cwS",
        "-tVgOWHgpc0W",
        "_2HO3H2WkkDC",
        "G9QnYzQBmqC6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/KK_C4_Spark_EDA_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj93_nN2wPV1"
      },
      "source": [
        "![alt text](https://github.com/Praxis-QR/RDWH/raw/main/images/YantraJaalBanner.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Sample Data\n",
        "An alternative approach is available at https://github.com/Praxis-QR/BDSN/blob/main/KK_C2A_Spark_WordCount_Alternative.ipynb"
      ],
      "metadata": {
        "id": "Y-gYEr36F06t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('Tested on ',datetime.now(pytz.timezone('Asia/Calcutta')))\n",
        "\n",
        "!python --version\n",
        "!lsb_release -a\n",
        "\n",
        "#check which version of MongoDB  is available\n",
        "#!apt-cache policy mongodb\n",
        "\n",
        "#check which versions of software are available\n",
        "#!pip3 index versions pyspark\n",
        "#!pip3 index versions pyngrok"
      ],
      "metadata": {
        "id": "dHceCHdUqREm",
        "outputId": "f78f171b-d617-4557-84b2-cd6380ee162a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested on  2024-01-18 09:09:02.698811+05:30\n",
            "Python 3.10.12\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 22.04.3 LTS\n",
            "Release:\t22.04\n",
            "Codename:\tjammy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOI8k9qicmu"
      },
      "source": [
        "# Spark Installation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Installation - Not Required, SKIP"
      ],
      "metadata": {
        "id": "GguG29b062na"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIjVxBSKIDsW"
      },
      "source": [
        "#!apt update > /dev/null\n",
        "#!apt install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAgQ-0fGhxWI"
      },
      "source": [
        "# Get latest and correct version of Spark\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "#!pip install -q pyspark\n",
        "\n",
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ClRT_Ari2Ys"
      },
      "source": [
        "# findspark route is no more required\n",
        "#import findspark\n",
        "#findspark.init()\n",
        "#\n",
        "#findspark.init('/content/spark-2.2.2-bin-hadoop2.7')\n",
        "#\n",
        "# https://stackoverflow.com/questions/42223498/findspark-init-indexerror-list-index-out-of-range-error\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simpler Install. Works"
      ],
      "metadata": {
        "id": "vI0evwwr7CpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 -q install pyngrok\n",
        "!pip3 -q install s3fs\n",
        "!pip3 -q install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KtBzIPRpF-W",
        "outputId": "6f0485e9-6cf0-4f8f-fd2d-8881b2a48cde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/75.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from pyspark.sql import SparkSession\n",
        "#\n",
        "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# note UI port switched from default 4040 to 4050 to avoid clash with ngrok\n",
        "#\n",
        "spark = SparkSession.builder.master(\"local[*]\").config('spark.ui.port', '4050').getOrCreate()\n",
        "#\n",
        "sc = spark.sparkContext\n",
        "#\n",
        "# The spark Console UI is available in the link that will be displayed in this cell.\n",
        "# If you do not wish to use the Console, you may skip the Tunnel part\n",
        "sc"
      ],
      "metadata": {
        "id": "JA26cSUf7Maq",
        "outputId": "d3593bef-0793-4991-841a-f8030e06f298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b8bebdb79422:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2QOKe1NRHn4"
      },
      "source": [
        "##Tunnel with ngrok <br>\n",
        "This part required ONLY if you need to access Spark Console<br>\n",
        "To get you ngrok token please visit https://dashboard.ngrok.com/login <br>\n",
        "and create a free account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG1ZwJ8yehyw"
      },
      "source": [
        "###Loading ngrok token from GDrive<br>\n",
        "this part may be skipped if ngrok can be placed directly in one of the two next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7uFjFW9RU9L",
        "outputId": "db5df8ef-bde8-44c3-88aa-6c19b1f6d7b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#\n",
        "#!ls /content/drive/'My Drive'/Praxis/WebCredentials/\n",
        "#\n",
        "!cp /content/drive/'My Drive'/Praxis/WebCredentials/ngrokToken.py ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXb94HvLSSBb"
      },
      "source": [
        "# credential file for Prithwis Mukerjee\n",
        "# this file needs to be uploaded into the VM\n",
        "\n",
        "from ngrokToken import ngrokToken\n",
        "\n",
        "#for the sake of privacy\n",
        "#the following credentials need to be stored in a text file called ngrokToken.py\n",
        "#in the format given below\n",
        "#in the Colab VM\n",
        "\n",
        "#otherwise, the values can be directly placed here\n",
        "\n",
        "#ngrokToken = 'xxxxxxxxxxxxxxx'   # uncomment this line and place your own credentials here\n",
        "#token is available at https://dashboard.ngrok.com/get-started/setup\n",
        "\n",
        "\n",
        "#print(ngrokToken)\n",
        "ngrokTokenCmd = 'ngrok authtoken '+ngrokToken"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuCKEn_dsfkm"
      },
      "source": [
        "###ngrok - python wrapper <br>\n",
        "this code adapted from https://towardsdatascience.com/quickly-share-ml-webapps-from-google-colab-using-ngrok-for-free-ae899ca2661a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sWPM5QvtS4B"
      },
      "source": [
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0ssMRt36k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae054fd-426b-4634-ad3c-b3f3d0295235"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "# you may place the token directly here\n",
        "#!ngrok authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "get_ipython().system_raw(ngrokTokenCmd)\n",
        "# Open a HTTP tunnel on the default port 80\n",
        "#public_url = ngrok.connect(port = '4050')\n",
        "public_url = ngrok.connect(4050)\n",
        "#This is where the Spark Console UI will be visible\n",
        "public_url"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://0dd1-34-118-242-101.ngrok-free.app\" -> \"http://localhost:4050\">"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL_D5j-oOn2V"
      },
      "source": [
        "The next four cells are not required. Mainly used to check on the status of the Tunnel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Ne_XhzuDGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244bc68a-e027-4559-db99-08f3eeb1015c"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tunnels\":[{\"name\":\"http-4050-7b6b18f4-59ba-42fd-8269-5f6dd6af7423\",\"ID\":\"f95df2af638ea911dcbe2d0913061c4d\",\"uri\":\"/api/tunnels/http-4050-7b6b18f4-59ba-42fd-8269-5f6dd6af7423\",\"public_url\":\"https://0dd1-34-118-242-101.ngrok-free.app\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO66r_yEftBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c990bf6-963d-41df-d856-dc092666ae8f"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://0dd1-34-118-242-101.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tQPpQ8q09V",
        "outputId": "f0e9a5df-2c68-4352-af7b-49b454f4ecdc"
      },
      "source": [
        "!ps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:01 node\n",
            "     17 ?        00:00:00 tail\n",
            "     55 ?        00:00:01 jupyter-noteboo\n",
            "     56 ?        00:00:00 dap_multiplexer\n",
            "     66 ?        00:00:03 python3\n",
            "     86 ?        00:00:00 python3\n",
            "   1074 ?        00:00:09 java\n",
            "   1171 ?        00:00:00 bash\n",
            "   1172 ?        00:00:00 drive\n",
            "   1173 ?        00:00:00 grep\n",
            "   1220 ?        00:00:00 fusermount <defunct>\n",
            "   1246 ?        00:00:00 drive\n",
            "   1299 ?        00:00:00 bash\n",
            "   1300 ?        00:00:00 tail\n",
            "   1301 ?        00:00:00 python3\n",
            "   1345 ?        00:00:00 ngrok\n",
            "   1361 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkMV2GxrI3L"
      },
      "source": [
        "!kill -9 1219"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKbXwFgI8WW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "Sourced from https://github.com/search?q=owner%3Ajigsawlabs-student%20pyspark&type=repositories"
      ],
      "metadata": {
        "id": "HffGBK-_i0uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -O netflix.csv \"https://raw.githubusercontent.com/jigsawlabs-student/pyspark-cluster-lab/main/netflix_titles.csv\"\n",
        "!wget \"https://github.com/Praxis-QR/BDSN/raw/main/Data2/NetFlix.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-d-O9qyi5wG",
        "outputId": "698bb431-21e8-437f-cd1e-56f27de4f59d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-18 03:42:27--  https://github.com/Praxis-QR/BDSN/raw/main/Data2/NetFlix.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/NetFlix.csv [following]\n",
            "--2024-01-18 03:42:27--  https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/NetFlix.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2992704 (2.9M) [text/plain]\n",
            "Saving to: ‘NetFlix.csv’\n",
            "\n",
            "NetFlix.csv         100%[===================>]   2.85M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-01-18 03:42:28 (43.9 MB/s) - ‘NetFlix.csv’ saved [2992704/2992704]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#df = pd.read_csv('s3://jigsaw-labs-student/supermarket_sales.csv')\n",
        "dfNetFlix = pd.read_csv('NetFlix.csv')\n",
        "dfNetFlix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cArJSIybjg_r",
        "outputId": "75de637b-915f-475f-f8f8-06cac032171f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7787, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://github.com/Praxis-QR/BDSN/raw/main/Data2/SuperMarketSales.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsDC8tYlq2we",
        "outputId": "6a6d78b9-8fa7-4a16-d4a3-a393a93f1030"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-18 03:46:01--  https://github.com/Praxis-QR/BDSN/raw/main/Data2/SuperMarketSales.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/SuperMarketSales.csv [following]\n",
            "--2024-01-18 03:46:01--  https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/SuperMarketSales.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130853 (128K) [text/plain]\n",
            "Saving to: ‘SuperMarketSales.csv’\n",
            "\n",
            "SuperMarketSales.cs 100%[===================>] 127.79K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-18 03:46:01 (5.38 MB/s) - ‘SuperMarketSales.csv’ saved [130853/130853]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfSuperMarket = pd.read_csv('SuperMarketSales.csv')\n",
        "dfSuperMarket.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l2bIHHPraDj",
        "outputId": "f92889d9-76c2-4027-f597-cf268f12b8c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://github.com/Praxis-QR/BDSN/raw/main/Data2/IMDBmovies.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_BSxPxirnuL",
        "outputId": "032d7ffd-f889-4d1e-8c0f-be2b44741ed5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-18 03:48:09--  https://github.com/Praxis-QR/BDSN/raw/main/Data2/IMDBmovies.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/IMDBmovies.csv [following]\n",
            "--2024-01-18 03:48:09--  https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Data2/IMDBmovies.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108557 (106K) [text/plain]\n",
            "Saving to: ‘IMDBmovies.csv’\n",
            "\n",
            "IMDBmovies.csv      100%[===================>] 106.01K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-18 03:48:09 (4.66 MB/s) - ‘IMDBmovies.csv’ saved [108557/108557]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfIMDB = pd.read_csv('IMDBmovies.csv')\n",
        "dfIMDB.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk3d15qSr2Nc",
        "outputId": "435bd259-4ab4-4d69-b4b6-a44b04eb0e75"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('SuperMarketSales.csv', sep=',', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "C8RVZStSkSoc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSMS = pd.read_csv('SuperMarketSales.csv')"
      ],
      "metadata": {
        "id": "eeaeg8ohkiWy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"s3://jigsaw-labs-student/imdb_movies.csv\")"
      ],
      "metadata": {
        "id": "3gnL6u4slyvC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('IMDBmovies.csv', sep=',', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "UZhtI7jal5YS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBb0xKLi9BW"
      },
      "source": [
        "# Data Input - Three options, use only 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRvq6-Cd5cwS"
      },
      "source": [
        "##Local Machine\n",
        "Please upload a .txt file from your desktop to the VM using the upload feature of Colab. Without this, this set of commands will not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmB_erdoijn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856674a6-fa6f-44c2-ee12-c330bf60f7f5"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 223496\n",
            "drwx------  6 root root      4096 Aug 21 00:59 drive\n",
            "-rw-------  1 root root        64 Aug 21 00:59 ngrokToken.py\n",
            "drwxr-xr-x  2 root root      4096 Aug 21 00:59 __pycache__\n",
            "drwxr-xr-x  1 root root      4096 Aug 13 13:35 sample_data\n",
            "drwxr-xr-x 13 1000 1000      4096 May 24 04:45 spark-3.1.2-bin-hadoop3.2\n",
            "-rw-r--r--  1 root root 228834641 May 24 05:01 spark-3.1.2-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cetfRq2hToE"
      },
      "source": [
        "textRDD = sc.textFile(\"CY-033-28May2020-TextFile.txt\")\n",
        "#textRDD = sc.textFile(\"hobbit.txt\")\n",
        "#textRDD = spark.read.text('hobbit.txt').rdd\n",
        "# for an explanation of the alternate way to read text files\n",
        "# see this https://stackoverflow.com/questions/52665353/reading-a-text-file-in-spark/52669632#52669632"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiDK866KhToY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb7d6d6-6908-499e-907b-53e926a5c5a7"
      },
      "source": [
        "print (textRDD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CY-033-28May2020-TextFile.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylf23XX_o3m2"
      },
      "source": [
        "#textRDD.take(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVgOWHgpc0W"
      },
      "source": [
        "##Google Drive - Mount\n",
        "In this case, you can mount or connect Google drive and pull out a txt file from there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLUlMVwGpc0M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2QgW3PpfesD"
      },
      "source": [
        "#!ls /content/drive/\"My Drive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XHQchlpc0E"
      },
      "source": [
        "!ls /content/drive/\"My Drive\"/Praxis/\"Course - Big Data Spark\"/WordCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slfM2Xgcpcz0"
      },
      "source": [
        "!cat /content/drive/\"My Drive\"/Praxis/\"Course - Big Data Spark\"/WordCount/hobbit2.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luNYr9g-pczi"
      },
      "source": [
        "#textRDD = spark.read.text(\"/content/drive/My Drive/Praxis/Course - Big Data Spark/WordCount/hobbit2.txt\").rdd\n",
        "textRDD = sc.textFile(\"/content/drive/My Drive/Praxis/Course - Big Data Spark/WordCount/hobbit2.txt\")\n",
        "# for an explanation of the alternate way to read text files\n",
        "# see this https://stackoverflow.com/questions/52665353/reading-a-text-file-in-spark/52669632#52669632"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN6ZJ9v3pczT"
      },
      "source": [
        "textRDD.take(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0spX8yVNMyZw"
      },
      "source": [
        "##Google Drive - GDown / Git repository\n",
        "In this case, a file that has universal read access privileges is pulled from Google Drive without the need to login in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvA6zv4fM1fc"
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1RELUMtExjMTSfoWF765Hr8JwNCSL7AgH\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Chronotantra.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO61epWsOBUP"
      },
      "source": [
        "textRDD = sc.textFile(\"Chronotantra.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zykb54rCOLe3",
        "outputId": "438743f2-33dc-4ecd-cf65-02a292df4fb9"
      },
      "source": [
        "textRDD.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'Chronotantra ', '', 'Prithwis Mukerjee', '']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2HO3H2WkkDC"
      },
      "source": [
        "# Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAvPRM1-kqJo"
      },
      "source": [
        "from operator import add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Np0nEJhTpK"
      },
      "source": [
        "#def tokenize1(textz):\n",
        "#    return textz.value.split()\n",
        "def tokenize2(textz):\n",
        "    return textz.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fP_I0OhTpa"
      },
      "source": [
        "wordsRDD = textRDD.flatMap(tokenize2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl9ogplR7EGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaab433b-6d16-402e-acae-22c7075f51f7"
      },
      "source": [
        "print(wordsRDD)\n",
        "wordsRDD.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PythonRDD[3] at RDD at PythonRDD.scala:53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Chronotantra',\n",
              " 'Prithwis',\n",
              " 'Mukerjee',\n",
              " 'CHRONOTANTRA',\n",
              " 'A',\n",
              " 'science',\n",
              " 'fiction',\n",
              " 'novel',\n",
              " 'Published',\n",
              " 'by']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac8Rb_Uiooqs"
      },
      "source": [
        "#wordsRDD.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMCcwZrxhTp8"
      },
      "source": [
        "wc = wordsRDD.map(lambda x: (x,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qbQGoyhTqQ"
      },
      "source": [
        "#print (wc.toDebugString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcIoomB-hTqi"
      },
      "source": [
        "counts = wc.reduceByKey(add)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9ODw1hXhTq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44c8c9c-2ae7-4100-b59b-b9955226922a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chronotantra.txt  drive  ngrokToken.py\t__pycache__  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5683u2uKhTrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128bc08d-0015-45c6-e0bc-9a55c59e568a"
      },
      "source": [
        "# If running a program for the second time, the output directory needs to be deleted\n",
        "!rm -r CT-Out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'CT-Out': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wydu9UDDhTro"
      },
      "source": [
        "#counts.saveAsTextFile(\"hobbit-Out\")\n",
        "counts.saveAsTextFile(\"CT-Out\")\n",
        "#counts.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9QnYzQBmqC6"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ac3dQ2VmYda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c613bb15-d598-40b6-8afd-b105a0e77aab"
      },
      "source": [
        "# Output is visble here\n",
        "#!ls hobbit-Out\n",
        "!ls CT-Out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  part-00001\t_SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMkcg01rnBR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32eb883c-7e02-425b-ecbf-9bc75eb212e2"
      },
      "source": [
        "#!cat hobbit-Out/part-00001\n",
        "#!cat hobbit-Out/part-00001\n",
        "!head CT-Out/part-00001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Chronotantra', 2)\n",
            "('Prithwis', 5)\n",
            "('CHRONOTANTRA', 1)\n",
            "('A', 46)\n",
            "('fiction', 4)\n",
            "('Published', 1)\n",
            "('by', 190)\n",
            "('the', 3399)\n",
            "('Author', 2)\n",
            "('available', 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smdrOXSTiSPp"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZcQeS1hTuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6e671755-e07f-45fe-9078-13e97f3b0ae3"
      },
      "source": [
        "files.download(\"CT-Out/part-00000\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9893c9a0-b646-4d90-95b8-7c79fadab6a1\", \"part-00000\", 86891)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "yOGlEzx78E2M",
        "outputId": "2abe4076-4862-4edd-de87-45d984c6d9f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2023-11-03 14:15:14.763476+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKTZezaqMK_0"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself.\n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}