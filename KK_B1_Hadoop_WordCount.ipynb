{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B1 Hadoop WordCount",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/KK_B1_Hadoop_WordCount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOvxIBi-IJ8G"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwjvirExIQAM"
      },
      "source": [
        "#Hadoop\n",
        "This Notebook has all the codes required to install Hadoop in the Colab VM and execute the a WordCount program using the streaming API <br>\n",
        "The mapper.py and reducer.py programs are available in the authors G-Drive / Github and are downloaded as required<br>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5y3g-ySDmZ"
      },
      "source": [
        "##Acknowledgements\n",
        "Hadoop Installation from [Anjaly Sam's Github Repository](https://github.com/anjalysam/Hadoop) <br>\n",
        "\n",
        "To get the concept behind map-reduce see [this notebook](https://github.com/Praxis-QR/BDSN/blob/main/Basic_WordCount_Concept.ipynb) <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bT9M1yvyXG"
      },
      "source": [
        "# 1 Download, Install Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFZuorwF25e"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZAdD_cBMK",
        "outputId": "f61b948f-4e74-4865-a7f3-0e0ab2e074e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If there is an error in this cell, it is very likely that the version of hadoop has changed\n",
        "# Download the latest version of Hadoop and change the version numbers accordingly\n",
        "#wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "#!wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "!wget  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.2.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-25 06:10:17--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  18.5MB/s    in 35s     \n",
            "\n",
            "2022-04-25 06:10:53 (17.6 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pjQecX-LetK",
        "outputId": "fd863765-76d3-4d67-cd17-c35c2cb02b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /usr/local"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t   cuda-10.1  cuda-11.1  _gcs_config_ops.so  lib\tsbin   xgboost\n",
            "cuda\t   cuda-11    etc\t hadoop-3.3.2\t     licensing\tshare\n",
            "cuda-10.0  cuda-11.0  games\t include\t     man\tsrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6Dqbbrwqpe"
      },
      "source": [
        "# 2 Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUc19ZtcBG5"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez4T7Gs3RAn"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "# make sure that the version number is as downloaded \n",
        "#os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.0/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.2/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKOGAmCVhXZ4",
        "outputId": "430c2a7b-e4d0-4f7b-abd6-8b62acbc97f4"
      },
      "source": [
        "!echo $PATH"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFgpWGLhdhl",
        "outputId": "2d0abb2e-52e3-41a1-8fee-6c14506079d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# Get the current_path from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.2/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj00rPPZyEWZ"
      },
      "source": [
        "# 3 Test Hadoop Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf-zK7NcBDF"
      },
      "source": [
        "#Running Hadoop - Test RUN, not doing anything at all\n",
        "#!/usr/local/hadoop-3.3.0/bin/hadoop\n",
        "# UNCOMMENT the following line if you want to make sure that Hadoop is alive!\n",
        "#!hadoop"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3I6iqjGod-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a358f8d-7188-4310-f0cb-0e11e3454b0e"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "# Final output should be : Estimated value of Pi is 3.14157500000000000000\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000\n",
        "!hadoop jar /usr/local/hadoop-3.3.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.2.jar pi 16 100000"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Maps  = 16\n",
            "Samples per Map = 100000\n",
            "Wrote input for Map #0\n",
            "Wrote input for Map #1\n",
            "Wrote input for Map #2\n",
            "Wrote input for Map #3\n",
            "Wrote input for Map #4\n",
            "Wrote input for Map #5\n",
            "Wrote input for Map #6\n",
            "Wrote input for Map #7\n",
            "Wrote input for Map #8\n",
            "Wrote input for Map #9\n",
            "Wrote input for Map #10\n",
            "Wrote input for Map #11\n",
            "Wrote input for Map #12\n",
            "Wrote input for Map #13\n",
            "Wrote input for Map #14\n",
            "Wrote input for Map #15\n",
            "Starting Job\n",
            "2022-04-25 06:16:33,193 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-04-25 06:16:33,278 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-04-25 06:16:33,278 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-04-25 06:16:33,444 INFO input.FileInputFormat: Total input files to process : 16\n",
            "2022-04-25 06:16:33,457 INFO mapreduce.JobSubmitter: number of splits:16\n",
            "2022-04-25 06:16:33,624 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1852009494_0001\n",
            "2022-04-25 06:16:33,624 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-04-25 06:16:33,835 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-04-25 06:16:33,836 INFO mapreduce.Job: Running job: job_local1852009494_0001\n",
            "2022-04-25 06:16:33,843 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-04-25 06:16:33,851 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:33,851 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:33,852 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2022-04-25 06:16:33,941 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-04-25 06:16:33,941 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000000_0\n",
            "2022-04-25 06:16:33,968 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:33,968 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:33,994 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:33,999 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part3:0+118\n",
            "2022-04-25 06:16:34,083 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,083 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,083 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,083 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,083 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,088 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,142 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,142 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,142 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,142 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,142 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,149 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,163 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,165 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,165 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000000_0' done.\n",
            "2022-04-25 06:16:34,174 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=283466\n",
            "\t\tFILE: Number of bytes written=922756\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=204996608\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,174 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000000_0\n",
            "2022-04-25 06:16:34,174 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000001_0\n",
            "2022-04-25 06:16:34,177 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,177 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,177 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,178 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part13:0+118\n",
            "2022-04-25 06:16:34,258 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,258 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,258 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,258 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,259 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,260 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,279 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,279 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,279 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,279 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,279 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,281 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,283 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000001_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,286 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,286 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000001_0' done.\n",
            "2022-04-25 06:16:34,287 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=285685\n",
            "\t\tFILE: Number of bytes written=922816\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=310378496\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,287 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000001_0\n",
            "2022-04-25 06:16:34,287 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000002_0\n",
            "2022-04-25 06:16:34,290 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,291 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,291 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,292 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part0:0+118\n",
            "2022-04-25 06:16:34,369 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,370 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,370 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,370 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,370 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,371 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,377 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,377 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,378 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,378 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,378 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,379 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,385 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000002_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,386 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,386 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000002_0' done.\n",
            "2022-04-25 06:16:34,387 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=287904\n",
            "\t\tFILE: Number of bytes written=922876\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=415760384\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,387 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000002_0\n",
            "2022-04-25 06:16:34,387 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000003_0\n",
            "2022-04-25 06:16:34,388 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,388 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,388 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,391 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part11:0+118\n",
            "2022-04-25 06:16:34,472 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,472 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,472 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,472 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,472 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,473 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,478 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,478 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,478 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,478 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,478 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,480 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,485 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000003_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,487 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,487 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000003_0' done.\n",
            "2022-04-25 06:16:34,487 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=290123\n",
            "\t\tFILE: Number of bytes written=922936\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=521142272\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,487 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000003_0\n",
            "2022-04-25 06:16:34,487 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000004_0\n",
            "2022-04-25 06:16:34,490 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,490 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,490 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,492 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part1:0+118\n",
            "2022-04-25 06:16:34,558 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,558 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,558 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,558 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,558 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,559 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,565 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,565 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,565 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,565 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,565 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,567 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,571 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000004_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,572 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,573 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000004_0' done.\n",
            "2022-04-25 06:16:34,573 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=291830\n",
            "\t\tFILE: Number of bytes written=922996\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=626524160\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,573 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000004_0\n",
            "2022-04-25 06:16:34,573 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000005_0\n",
            "2022-04-25 06:16:34,574 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,574 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,575 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,576 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part4:0+118\n",
            "2022-04-25 06:16:34,643 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,643 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,643 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,643 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,643 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,644 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,648 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,648 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,648 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,648 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,648 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,650 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,651 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000005_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,652 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,653 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000005_0' done.\n",
            "2022-04-25 06:16:34,653 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=293537\n",
            "\t\tFILE: Number of bytes written=923056\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=731906048\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,653 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000005_0\n",
            "2022-04-25 06:16:34,653 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000006_0\n",
            "2022-04-25 06:16:34,658 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,658 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,658 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,659 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part6:0+118\n",
            "2022-04-25 06:16:34,734 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,734 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,734 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,734 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,734 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,735 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,744 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,744 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,744 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,744 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,744 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,745 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,747 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000006_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,751 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,751 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000006_0' done.\n",
            "2022-04-25 06:16:34,753 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=295244\n",
            "\t\tFILE: Number of bytes written=923116\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=837287936\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,753 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000006_0\n",
            "2022-04-25 06:16:34,753 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000007_0\n",
            "2022-04-25 06:16:34,761 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,761 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,761 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,763 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part12:0+118\n",
            "2022-04-25 06:16:34,841 INFO mapreduce.Job: Job job_local1852009494_0001 running in uber mode : false\n",
            "2022-04-25 06:16:34,848 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-04-25 06:16:34,849 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,849 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,849 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,849 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,849 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,852 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,860 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,860 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,860 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,860 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,860 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,861 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,864 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000007_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,866 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,867 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000007_0' done.\n",
            "2022-04-25 06:16:34,868 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000007_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=296951\n",
            "\t\tFILE: Number of bytes written=923176\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=942669824\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,868 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000007_0\n",
            "2022-04-25 06:16:34,868 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000008_0\n",
            "2022-04-25 06:16:34,869 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,869 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,870 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,871 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part8:0+118\n",
            "2022-04-25 06:16:34,939 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:34,939 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:34,939 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:34,939 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,939 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:34,940 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:34,948 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:34,949 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:34,949 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:34,949 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:34,949 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:34,950 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:34,953 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000008_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:34,955 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:34,955 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000008_0' done.\n",
            "2022-04-25 06:16:34,955 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000008_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=298146\n",
            "\t\tFILE: Number of bytes written=923236\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1048051712\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:34,956 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000008_0\n",
            "2022-04-25 06:16:34,956 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000009_0\n",
            "2022-04-25 06:16:34,958 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:34,958 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:34,959 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:34,960 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part2:0+118\n",
            "2022-04-25 06:16:35,036 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,036 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,036 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,036 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,036 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,038 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,042 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,042 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,042 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,042 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,042 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,044 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,046 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000009_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,047 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,047 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000009_0' done.\n",
            "2022-04-25 06:16:35,047 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000009_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=299341\n",
            "\t\tFILE: Number of bytes written=923296\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1153433600\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,047 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000009_0\n",
            "2022-04-25 06:16:35,048 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000010_0\n",
            "2022-04-25 06:16:35,050 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,050 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,050 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,051 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part5:0+118\n",
            "2022-04-25 06:16:35,119 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,119 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,119 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,119 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,119 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,120 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,130 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,130 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,130 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,130 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,130 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,131 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,133 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000010_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,134 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,134 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000010_0' done.\n",
            "2022-04-25 06:16:35,135 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000010_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=300536\n",
            "\t\tFILE: Number of bytes written=923356\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1258815488\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,135 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000010_0\n",
            "2022-04-25 06:16:35,135 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000011_0\n",
            "2022-04-25 06:16:35,138 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,139 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,140 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,141 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part15:0+118\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,211 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,218 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,218 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,218 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,218 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,218 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,219 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,221 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000011_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,223 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,223 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000011_0' done.\n",
            "2022-04-25 06:16:35,224 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000011_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=301731\n",
            "\t\tFILE: Number of bytes written=923416\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1364197376\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,224 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000011_0\n",
            "2022-04-25 06:16:35,224 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000012_0\n",
            "2022-04-25 06:16:35,225 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,225 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,225 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,226 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part7:0+118\n",
            "2022-04-25 06:16:35,294 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,294 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,294 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,294 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,294 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,296 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,305 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,306 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,306 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,306 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,306 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,307 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,309 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000012_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,310 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,310 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000012_0' done.\n",
            "2022-04-25 06:16:35,311 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000012_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=302414\n",
            "\t\tFILE: Number of bytes written=923476\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1469579264\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,311 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000012_0\n",
            "2022-04-25 06:16:35,311 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000013_0\n",
            "2022-04-25 06:16:35,313 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,313 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,313 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,316 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part14:0+118\n",
            "2022-04-25 06:16:35,381 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,381 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,381 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,381 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,381 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,382 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,386 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,386 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,386 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,386 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,386 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,387 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,388 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000013_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,391 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,391 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000013_0' done.\n",
            "2022-04-25 06:16:35,392 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000013_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=303097\n",
            "\t\tFILE: Number of bytes written=923536\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1574961152\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,392 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000013_0\n",
            "2022-04-25 06:16:35,392 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000014_0\n",
            "2022-04-25 06:16:35,393 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,393 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,393 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,395 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part9:0+118\n",
            "2022-04-25 06:16:35,462 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,462 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,462 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,462 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,462 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,464 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,469 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,469 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,469 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,469 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,469 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,470 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,472 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000014_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,473 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,473 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000014_0' done.\n",
            "2022-04-25 06:16:35,473 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000014_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=303780\n",
            "\t\tFILE: Number of bytes written=923596\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1680343040\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,473 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000014_0\n",
            "2022-04-25 06:16:35,473 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_m_000015_0\n",
            "2022-04-25 06:16:35,476 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,476 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,477 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,480 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1650867392481_1527061860/in/part10:0+118\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:16:35,550 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:16:35,556 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:16:35,557 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:16:35,557 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:16:35,557 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-04-25 06:16:35,557 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-04-25 06:16:35,561 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:16:35,566 INFO mapred.Task: Task:attempt_local1852009494_0001_m_000015_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,569 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-04-25 06:16:35,569 INFO mapred.Task: Task 'attempt_local1852009494_0001_m_000015_0' done.\n",
            "2022-04-25 06:16:35,569 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_m_000015_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=304463\n",
            "\t\tFILE: Number of bytes written=923656\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=129\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1785724928\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-04-25 06:16:35,570 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_m_000015_0\n",
            "2022-04-25 06:16:35,570 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-04-25 06:16:35,574 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-04-25 06:16:35,574 INFO mapred.LocalJobRunner: Starting task: attempt_local1852009494_0001_r_000000_0\n",
            "2022-04-25 06:16:35,583 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:16:35,583 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:16:35,583 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:16:35,586 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2292dc5c\n",
            "2022-04-25 06:16:35,588 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-04-25 06:16:35,614 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-04-25 06:16:35,626 INFO reduce.EventFetcher: attempt_local1852009494_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-04-25 06:16:35,694 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000011_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,702 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000011_0\n",
            "2022-04-25 06:16:35,703 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24\n",
            "2022-04-25 06:16:35,705 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000004_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,709 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000004_0\n",
            "2022-04-25 06:16:35,710 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 2, commitMemory -> 24, usedMemory ->48\n",
            "2022-04-25 06:16:35,711 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000010_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,716 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000010_0\n",
            "2022-04-25 06:16:35,717 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 3, commitMemory -> 48, usedMemory ->72\n",
            "2022-04-25 06:16:35,718 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000003_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,727 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000003_0\n",
            "2022-04-25 06:16:35,727 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 4, commitMemory -> 72, usedMemory ->96\n",
            "2022-04-25 06:16:35,728 WARN io.ReadaheadPool: Failed readahead on ifile\n",
            "EBADF: Bad file descriptor\n",
            "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
            "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:419)\n",
            "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:296)\n",
            "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:220)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:748)\n",
            "2022-04-25 06:16:35,728 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000009_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,731 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000009_0\n",
            "2022-04-25 06:16:35,731 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 5, commitMemory -> 96, usedMemory ->120\n",
            "2022-04-25 06:16:35,732 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000015_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,732 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000015_0\n",
            "2022-04-25 06:16:35,732 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 6, commitMemory -> 120, usedMemory ->144\n",
            "2022-04-25 06:16:35,733 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000002_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,734 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000002_0\n",
            "2022-04-25 06:16:35,734 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 7, commitMemory -> 144, usedMemory ->168\n",
            "2022-04-25 06:16:35,735 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000008_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,735 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000008_0\n",
            "2022-04-25 06:16:35,735 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 8, commitMemory -> 168, usedMemory ->192\n",
            "2022-04-25 06:16:35,736 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000001_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,737 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000001_0\n",
            "2022-04-25 06:16:35,737 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 9, commitMemory -> 192, usedMemory ->216\n",
            "2022-04-25 06:16:35,738 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000014_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,739 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000014_0\n",
            "2022-04-25 06:16:35,740 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 10, commitMemory -> 216, usedMemory ->240\n",
            "2022-04-25 06:16:35,741 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000007_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,741 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000007_0\n",
            "2022-04-25 06:16:35,743 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 11, commitMemory -> 240, usedMemory ->264\n",
            "2022-04-25 06:16:35,746 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000013_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,747 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000013_0\n",
            "2022-04-25 06:16:35,747 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 12, commitMemory -> 264, usedMemory ->288\n",
            "2022-04-25 06:16:35,748 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000000_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,751 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000000_0\n",
            "2022-04-25 06:16:35,751 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 13, commitMemory -> 288, usedMemory ->312\n",
            "2022-04-25 06:16:35,752 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000006_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,752 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000006_0\n",
            "2022-04-25 06:16:35,752 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 14, commitMemory -> 312, usedMemory ->336\n",
            "2022-04-25 06:16:35,754 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000012_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,755 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000012_0\n",
            "2022-04-25 06:16:35,755 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 15, commitMemory -> 336, usedMemory ->360\n",
            "2022-04-25 06:16:35,757 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1852009494_0001_m_000005_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-04-25 06:16:35,758 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1852009494_0001_m_000005_0\n",
            "2022-04-25 06:16:35,758 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 16, commitMemory -> 360, usedMemory ->384\n",
            "2022-04-25 06:16:35,760 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-04-25 06:16:35,761 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-04-25 06:16:35,761 INFO reduce.MergeManagerImpl: finalMerge called with 16 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-04-25 06:16:35,768 INFO mapred.Merger: Merging 16 sorted segments\n",
            "2022-04-25 06:16:35,769 INFO mapred.Merger: Down to the last merge-pass, with 16 segments left of total size: 336 bytes\n",
            "2022-04-25 06:16:35,770 INFO reduce.MergeManagerImpl: Merged 16 segments, 384 bytes to disk to satisfy reduce memory limit\n",
            "2022-04-25 06:16:35,770 INFO reduce.MergeManagerImpl: Merging 1 files, 358 bytes from disk\n",
            "2022-04-25 06:16:35,771 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-04-25 06:16:35,771 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-04-25 06:16:35,771 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 351 bytes\n",
            "2022-04-25 06:16:35,772 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-04-25 06:16:35,775 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-04-25 06:16:35,783 INFO mapred.Task: Task:attempt_local1852009494_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-04-25 06:16:35,784 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-04-25 06:16:35,784 INFO mapred.Task: Task attempt_local1852009494_0001_r_000000_0 is allowed to commit now\n",
            "2022-04-25 06:16:35,785 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1852009494_0001_r_000000_0' to file:/content/QuasiMonteCarlo_1650867392481_1527061860/out\n",
            "2022-04-25 06:16:35,785 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2022-04-25 06:16:35,785 INFO mapred.Task: Task 'attempt_local1852009494_0001_r_000000_0' done.\n",
            "2022-04-25 06:16:35,786 INFO mapred.Task: Final Counters for attempt_local1852009494_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=305781\n",
            "\t\tFILE: Number of bytes written=924253\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=32\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=23\n",
            "\t\tTotal committed heap usage (bytes)=1839202304\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "2022-04-25 06:16:35,786 INFO mapred.LocalJobRunner: Finishing task: attempt_local1852009494_0001_r_000000_0\n",
            "2022-04-25 06:16:35,786 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-04-25 06:16:35,852 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-04-25 06:16:35,853 INFO mapreduce.Job: Job job_local1852009494_0001 completed successfully\n",
            "2022-04-25 06:16:35,877 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=5044029\n",
            "\t\tFILE: Number of bytes written=15695549\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=16\n",
            "\t\tMap output records=32\n",
            "\t\tMap output bytes=288\n",
            "\t\tMap output materialized bytes=448\n",
            "\t\tInput split bytes=2054\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=64\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=23\n",
            "\t\tTotal committed heap usage (bytes)=17764974592\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=2080\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "Job Finished in 2.784 seconds\n",
            "Estimated value of Pi is 3.14157500000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC9WSzgMprwr"
      },
      "source": [
        "# 4 Run WordCount with Hadoop\n",
        "Instead of using Java for Map and Reduce methods, we use the streaming API of Hadoop and two simple python programs as mapper.py and reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxloM8fzqORx"
      },
      "source": [
        "# get mapper.py reducer.py from G_drive\n",
        "#!gdown https://drive.google.com/uc?id=1VTzQ18cWAj6L29ncW6sABy-ITmDCcv5r\n",
        "#!gdown https://drive.google.com/uc?id=1Or8Cbf9AsFMHStjMzDw3pXCd6TZ0dqxJ\n",
        "\n",
        "#get mapper.py reducer.py from this git repository\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/mapper.py\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/reducer.py"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRWPIMj9qpZK"
      },
      "source": [
        "# to see the codes, uncomment the following lines\n",
        "#!cat mapper.py\n",
        "#print(\"\\n----------------------    see above for mapper, see below for reducer\")\n",
        "#!cat reducer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQ_4eaxqlCW"
      },
      "source": [
        "# python codes are made executable\n",
        "!chmod u+rwx /content/mapper.py\n",
        "!chmod u+rwx /content/reducer.py"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yfxo4CJrCtJ"
      },
      "source": [
        "# get a simple txt file as data for word count\n",
        "# or you can upload your own\n",
        "#!gdown https://drive.google.com/uc?id=1R5W0UVH2S3JjPxerqyX4ue5y6tMt0Wkk\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Chronotantra.txt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W38-6u0KrSrp",
        "outputId": "a5f805f2-8338-44c5-a36f-f0fecc7bceb6"
      },
      "source": [
        "# locate the streaming jar file\n",
        "!find / -name 'hadoop-streaming*.jar'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/31/task/31/net’: Invalid argument\n",
            "find: ‘/proc/31/net’: Invalid argument\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/sources/hadoop-streaming-3.3.2-sources.jar\n",
            "/usr/local/hadoop-3.3.2/share/hadoop/tools/sources/hadoop-streaming-3.3.2-test-sources.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h60r05EPk-xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2492b4d0-f31d-43db-bda1-8fb17d99b36d"
      },
      "source": [
        "# remove output directories\n",
        "!rm -r wc_out\n",
        "!rm -r wc2_out"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'wc_out': No such file or directory\n",
            "rm: cannot remove 'wc2_out': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH-I6ow7rl9k",
        "outputId": "45971aad-943d-4287-c80d-2d7ebadb25b9"
      },
      "source": [
        "# execute the streaming jar with proper parameters\n",
        "# four parameters are input file, output directory, the mapper progra, the reducer program\n",
        "#\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/hobbit.txt -output /content/wc_out -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/Chronotantra.txt -output /content/wc_out -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/Chronotantra.txt -output /content/wc_out  -mapper 'python mapper.py'  -reducer 'python reducer.py'\n",
        "!hadoop jar /usr/local/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar -input /content/Chronotantra.txt -output /content/wc_out  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-25 06:18:40,497 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-04-25 06:18:40,598 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-04-25 06:18:40,598 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-04-25 06:18:40,616 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-04-25 06:18:40,809 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2022-04-25 06:18:40,831 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-04-25 06:18:41,045 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local921880145_0001\n",
            "2022-04-25 06:18:41,046 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-04-25 06:18:41,237 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-04-25 06:18:41,239 INFO mapreduce.Job: Running job: job_local921880145_0001\n",
            "2022-04-25 06:18:41,246 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-04-25 06:18:41,248 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2022-04-25 06:18:41,252 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:18:41,252 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:18:41,293 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-04-25 06:18:41,297 INFO mapred.LocalJobRunner: Starting task: attempt_local921880145_0001_m_000000_0\n",
            "2022-04-25 06:18:41,329 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:18:41,329 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:18:41,369 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:18:41,378 INFO mapred.MapTask: Processing split: file:/content/Chronotantra.txt:0+353890\n",
            "2022-04-25 06:18:41,404 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2022-04-25 06:18:41,471 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-04-25 06:18:41,471 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-04-25 06:18:41,471 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-04-25 06:18:41,471 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-04-25 06:18:41,471 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-04-25 06:18:41,475 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-04-25 06:18:41,483 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2022-04-25 06:18:41,487 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2022-04-25 06:18:41,490 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2022-04-25 06:18:41,490 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2022-04-25 06:18:41,491 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2022-04-25 06:18:41,492 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2022-04-25 06:18:41,492 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2022-04-25 06:18:41,495 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2022-04-25 06:18:41,495 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2022-04-25 06:18:41,495 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2022-04-25 06:18:41,496 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2022-04-25 06:18:41,496 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-04-25 06:18:41,497 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2022-04-25 06:18:41,528 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:41,528 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:41,529 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:42,245 INFO mapreduce.Job: Job job_local921880145_0001 running in uber mode : false\n",
            "2022-04-25 06:18:42,246 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2022-04-25 06:18:42,809 INFO streaming.PipeMapRed: Records R/W=971/1\n",
            "2022-04-25 06:18:42,830 INFO streaming.PipeMapRed: R/W/S=1000/1146/0 in:1000=1000/1 [rec/s] out:1146=1146/1 [rec/s]\n",
            "2022-04-25 06:18:43,099 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-04-25 06:18:43,099 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-04-25 06:18:43,103 INFO mapred.LocalJobRunner: \n",
            "2022-04-25 06:18:43,103 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-04-25 06:18:43,103 INFO mapred.MapTask: Spilling map output\n",
            "2022-04-25 06:18:43,103 INFO mapred.MapTask: bufstart = 0; bufend = 261471; bufvoid = 104857600\n",
            "2022-04-25 06:18:43,103 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26100800(104403200); length = 113597/6553600\n",
            "2022-04-25 06:18:43,251 INFO mapred.MapTask: Finished spill 0\n",
            "2022-04-25 06:18:43,267 INFO mapred.Task: Task:attempt_local921880145_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-04-25 06:18:43,271 INFO mapred.LocalJobRunner: Records R/W=971/1\n",
            "2022-04-25 06:18:43,271 INFO mapred.Task: Task 'attempt_local921880145_0001_m_000000_0' done.\n",
            "2022-04-25 06:18:43,280 INFO mapred.Task: Final Counters for attempt_local921880145_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=495269\n",
            "\t\tFILE: Number of bytes written=1096832\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2647\n",
            "\t\tMap output records=28400\n",
            "\t\tMap output bytes=261471\n",
            "\t\tMap output materialized bytes=318277\n",
            "\t\tInput split bytes=82\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=28400\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=10\n",
            "\t\tTotal committed heap usage (bytes)=204996608\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=353890\n",
            "2022-04-25 06:18:43,280 INFO mapred.LocalJobRunner: Finishing task: attempt_local921880145_0001_m_000000_0\n",
            "2022-04-25 06:18:43,281 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-04-25 06:18:43,284 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-04-25 06:18:43,285 INFO mapred.LocalJobRunner: Starting task: attempt_local921880145_0001_r_000000_0\n",
            "2022-04-25 06:18:43,295 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-04-25 06:18:43,296 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-04-25 06:18:43,297 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-04-25 06:18:43,302 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@703637ff\n",
            "2022-04-25 06:18:43,304 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-04-25 06:18:43,322 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-04-25 06:18:43,332 INFO reduce.EventFetcher: attempt_local921880145_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-04-25 06:18:43,371 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local921880145_0001_m_000000_0 decomp: 318273 len: 318277 to MEMORY\n",
            "2022-04-25 06:18:43,375 INFO reduce.InMemoryMapOutput: Read 318273 bytes from map-output for attempt_local921880145_0001_m_000000_0\n",
            "2022-04-25 06:18:43,376 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 318273, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->318273\n",
            "2022-04-25 06:18:43,382 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-04-25 06:18:43,385 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-04-25 06:18:43,385 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-04-25 06:18:43,394 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-04-25 06:18:43,394 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 318269 bytes\n",
            "2022-04-25 06:18:43,438 INFO reduce.MergeManagerImpl: Merged 1 segments, 318273 bytes to disk to satisfy reduce memory limit\n",
            "2022-04-25 06:18:43,438 INFO reduce.MergeManagerImpl: Merging 1 files, 318277 bytes from disk\n",
            "2022-04-25 06:18:43,439 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-04-25 06:18:43,439 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-04-25 06:18:43,440 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 318269 bytes\n",
            "2022-04-25 06:18:43,440 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-04-25 06:18:43,448 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2022-04-25 06:18:43,451 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2022-04-25 06:18:43,453 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2022-04-25 06:18:43,490 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:43,490 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:43,496 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:43,503 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:43,526 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-04-25 06:18:43,610 INFO streaming.PipeMapRed: Records R/W=14053/1\n",
            "2022-04-25 06:18:43,726 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-04-25 06:18:43,727 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-04-25 06:18:43,729 INFO mapred.Task: Task:attempt_local921880145_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-04-25 06:18:43,730 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-04-25 06:18:43,730 INFO mapred.Task: Task attempt_local921880145_0001_r_000000_0 is allowed to commit now\n",
            "2022-04-25 06:18:43,732 INFO output.FileOutputCommitter: Saved output of task 'attempt_local921880145_0001_r_000000_0' to file:/content/wc_out\n",
            "2022-04-25 06:18:43,733 INFO mapred.LocalJobRunner: Records R/W=14053/1 > reduce\n",
            "2022-04-25 06:18:43,733 INFO mapred.Task: Task 'attempt_local921880145_0001_r_000000_0' done.\n",
            "2022-04-25 06:18:43,734 INFO mapred.Task: Final Counters for attempt_local921880145_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1131855\n",
            "\t\tFILE: Number of bytes written=1487543\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=6994\n",
            "\t\tReduce shuffle bytes=318277\n",
            "\t\tReduce input records=28400\n",
            "\t\tReduce output records=6994\n",
            "\t\tSpilled Records=28400\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=204996608\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=72434\n",
            "2022-04-25 06:18:43,734 INFO mapred.LocalJobRunner: Finishing task: attempt_local921880145_0001_r_000000_0\n",
            "2022-04-25 06:18:43,734 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-04-25 06:18:44,249 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-04-25 06:18:44,250 INFO mapreduce.Job: Job job_local921880145_0001 completed successfully\n",
            "2022-04-25 06:18:44,259 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1627124\n",
            "\t\tFILE: Number of bytes written=2584375\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2647\n",
            "\t\tMap output records=28400\n",
            "\t\tMap output bytes=261471\n",
            "\t\tMap output materialized bytes=318277\n",
            "\t\tInput split bytes=82\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=6994\n",
            "\t\tReduce shuffle bytes=318277\n",
            "\t\tReduce input records=28400\n",
            "\t\tReduce output records=6994\n",
            "\t\tSpilled Records=56800\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=10\n",
            "\t\tTotal committed heap usage (bytes)=409993216\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=353890\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=72434\n",
            "2022-04-25 06:18:44,259 INFO streaming.StreamJob: Output directory: /content/wc_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2DTo_GsBot",
        "outputId": "b28aedd6-b564-4aa6-99a0-656495a82902"
      },
      "source": [
        "# check output directory\n",
        "!ls wc_out"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91LjuJnlsKGz",
        "outputId": "86b094b8-9262-4ce2-ce99-ba48597ac421"
      },
      "source": [
        "# see actual output\n",
        "#!tail wc_out/part-00000\n",
        "!head wc_out/part-00000"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t8\n",
            "10\t2\n",
            "100\t2\n",
            "1000\t1\n",
            "105\t1\n",
            "108\t2\n",
            "109\t1\n",
            "11\t1\n",
            "110\t2\n",
            "113\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbaMQ1lWpB7O"
      },
      "source": [
        "### Sorting the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-kLgmOpLw8"
      },
      "source": [
        "#https://www.geeksforgeeks.org/sort-command-linuxunix-examples/\n",
        "!sort -nr -k 2 -t$'\\t' wc_out/part-00000 > sorted.txt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K09MH8h4qNfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d960e7a-b741-472e-d39f-c7225e7f0780"
      },
      "source": [
        "!head -30 sorted.txt\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "would\t346\n",
            "could\t247\n",
            "one\t198\n",
            "time\t156\n",
            "like\t145\n",
            "know\t144\n",
            "us\t134\n",
            "mars\t119\n",
            "back\t106\n",
            "even\t105\n",
            "world\t97\n",
            "something\t95\n",
            "see\t95\n",
            "well\t93\n",
            "hermit\t93\n",
            "two\t87\n",
            "people\t86\n",
            "course\t84\n",
            "around\t84\n",
            "way\t82\n",
            "first\t80\n",
            "really\t79\n",
            "new\t76\n",
            "little\t74\n",
            "long\t73\n",
            "still\t71\n",
            "information\t70\n",
            "ai\t67\n",
            "good\t63\n",
            "earth\t60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZN0vwE2pxHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec36cdc8-6570-4e4d-e18a-80d0c42087df"
      },
      "source": [
        "!tail -30 sorted.txt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2150\t1\n",
            "214\t1\n",
            "206\t1\n",
            "205\t1\n",
            "2019\t1\n",
            "2018\t1\n",
            "2007\t1\n",
            "20062007\t1\n",
            "2000\t1\n",
            "1999\t1\n",
            "1970s\t1\n",
            "1956\t1\n",
            "187\t1\n",
            "186\t1\n",
            "17866\t1\n",
            "156\t1\n",
            "155\t1\n",
            "15\t1\n",
            "150\t1\n",
            "1493\t1\n",
            "133\t1\n",
            "132\t1\n",
            "12th\t1\n",
            "12700\t1\n",
            "115\t1\n",
            "113\t1\n",
            "11\t1\n",
            "109\t1\n",
            "105\t1\n",
            "1000\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEShQrGRJio3"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}