{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B2 Hadoop and Hive",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/KK_B2_Hadoop_and_Hive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOvxIBi-IJ8G"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwjvirExIQAM"
      },
      "source": [
        "#Hive with Hadoop\n",
        "This notebook has all the codes / commands required to install Hadoop and Hive <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5y3g-ySDmZ"
      },
      "source": [
        "##Acknowledgements\n",
        "Hadoop Installation from [Anjaly Sam's Github Repository](https://github.com/anjalysam/Hadoop) <br>\n",
        "Hive Installation from [PhoenixNAP](https://phoenixnap.com/kb/install-hive-on-ubuntu) website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPIGP-mwKBD"
      },
      "source": [
        "#1 Hadoop\n",
        "Hadoop is a pre-requisite for Hive <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bT9M1yvyXG"
      },
      "source": [
        "## 1.1 Download, Install Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFZuorwF25e"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZAdD_cBMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5755fa-7a98-4a93-f931-ee1d62875eb4"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "# Change the version number in this and subsequent cells\n",
        "#\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.2.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-07 05:23:02--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  22.9MB/s    in 2m 21s  \n",
            "\n",
            "2022-10-07 05:25:23 (4.31 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6Dqbbrwqpe"
      },
      "source": [
        "## 1.2 Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUc19ZtcBG5"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez4T7Gs3RAn"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.2/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFgpWGLhdhl",
        "outputId": "152a5610-d875-4cd8-853a-367c91858cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# get current_path from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "#current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin'\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "#os.environ[\"PATH\"] = new_path\n",
        "\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZw3LI_91C8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj00rPPZyEWZ"
      },
      "source": [
        "## 1.3 Test Hadoop Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf-zK7NcBDF"
      },
      "source": [
        "#Running Hadoop - Test RUN, not doing anything at all\n",
        "#!/usr/local/hadoop-3.3.0/bin/hadoop\n",
        "# UNCOMMENT the following line if you want to make sure that Hadoop is alive!\n",
        "#!hadoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3I6iqjGod-"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUlA5c3yRCx1"
      },
      "source": [
        "#2 Hive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pURJ-sKVsymi"
      },
      "source": [
        "## 2.1 Download, Install HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFsywGzPRaYp",
        "outputId": "f8f16947-0ca6-488e-e839-da1894d923f3"
      },
      "source": [
        "# Download and Unzip the correct version and unzip\n",
        "!wget https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
        "!tar xzf apache-hive-3.1.2-bin.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-07 05:26:18--  https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278813748 (266M) [application/x-gzip]\n",
            "Saving to: ‘apache-hive-3.1.2-bin.tar.gz’\n",
            "\n",
            "apache-hive-3.1.2-b 100%[===================>] 265.90M  24.0MB/s    in 12s     \n",
            "\n",
            "2022-10-07 05:26:30 (22.1 MB/s) - ‘apache-hive-3.1.2-bin.tar.gz’ saved [278813748/278813748]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq6QYCVetNED"
      },
      "source": [
        "## 2.2 Set Environment *Variables*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qROUu4vSdEU",
        "outputId": "4f7469d5-0cd0-45c2-c88b-eab3eceae9d3"
      },
      "source": [
        "# Make sure that the version number is correct and is as downloaded\n",
        "os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3pKQ9PTBfR",
        "outputId": "41b8c2f5-07fe-4503-ad4f-015ab5c3c529"
      },
      "source": [
        "# current_path is set from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "#current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/'\n",
        "#new_path = current_path+':/content/apache-hive-3.1.2-bin/bin'\n",
        "#os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH\n",
        "\n",
        "\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/content/apache-hive-3.1.2-bin/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/\n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/:/content/apache-hive-3.1.2-bin/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfiA2LItT_L2",
        "outputId": "068e5ef5-9903-4e12-8cf3-4f7e91746c0b"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.2/\n",
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AryjHG4ltfEe"
      },
      "source": [
        "## 2.3 Set up HDFS Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dry58UPMVTat",
        "outputId": "0dfab850-9f35-4353-ef33-7d266f8afd9c"
      },
      "source": [
        "!hdfs dfs -mkdir /tmp\n",
        "!hdfs dfs -chmod g+w /tmp\n",
        "#!hdfs dfs -ls /\n",
        "!hdfs dfs -mkdir -p /content/warehouse\n",
        "!hdfs dfs -chmod g+w /content/warehouse\n",
        "#!hdfs dfs -ls /content/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: `/tmp': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VrvjhfG2JXs"
      },
      "source": [
        "## 2.4 Initialise HIVE - note and fix errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLX7AvL8YLMY"
      },
      "source": [
        "# TYPE this command, do not copy and paste. Non printing characters cause havoc \n",
        "# There will be two errors, that we will fix\n",
        "# UNCOMMENT the following line if you WISH TO SEE the errors\n",
        "#!schematool -initSchema -dbType derby\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v21CxgGLuJPQ"
      },
      "source": [
        "### 2.4.1 Fix One Warning, One Error \n",
        "SLF4J is duplicate, need to locate them and remove one <br>\n",
        "Guava jar version is low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Becy3BABuE8b",
        "outputId": "d6a15fd5-ffaa-4ecf-c3f0-5ddb63960949"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HIVE_HOME/lib/*slf4j*"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/jul-to-slf4j-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-api-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar\n",
            "/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUomnHGu4kR"
      },
      "source": [
        "# removed the logging jar from Hive, retaining the Hadoop jar\n",
        "!mv /content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar ./"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwLAYh7TY4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14525003-d87a-4505-8aa5-9a82def912f8"
      },
      "source": [
        "# guava jar needs to above v 20\n",
        "# https://stackoverflow.com/questions/45247193/nosuchmethoderror-com-google-common-base-preconditions-checkargumentzljava-lan\n",
        "!ls $HIVE_HOME/lib/gu*"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin/lib/guava-19.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpmyrbkZFad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc8e285-6f06-41ac-ec36-34b64682027e"
      },
      "source": [
        "# the one available with Hadoop is better, v 27\n",
        "!ls $HADOOP_HOME/share/hadoop/hdfs/lib/gu*"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/hdfs/lib/guava-27.0-jre.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ3Ex1vyZeZG"
      },
      "source": [
        "# Remove the Hive Guava and replace with Hadoop Guava\n",
        "!mv $HIVE_HOME/lib/guava-19.0.jar ./\n",
        "!cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdtNOXy8v4iD"
      },
      "source": [
        "##2.5 Initialize HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tzw4XkApRg3",
        "outputId": "f10da121-9067-4b46-d189-c5c62417c67c"
      },
      "source": [
        "#Type this command, dont copy-paste\n",
        "# Non printing characters inside the command will give totally illogical errors\n",
        "!schematool -initSchema -dbType derby"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metastore connection URL:\t jdbc:derby:;databaseName=metastore_db;create=true\n",
            "Metastore Connection Driver :\t org.apache.derby.jdbc.EmbeddedDriver\n",
            "Metastore connection User:\t APP\n",
            "Starting metastore schema initialization to 3.1.0\n",
            "Initialization script hive-schema-3.1.0.derby.sql\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Initialization script completed\n",
            "schemaTool completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALF720ewT_-"
      },
      "source": [
        "## 2.6 Test HIVE \n",
        "1. Create database\n",
        "2. Create table\n",
        "3. Insert data\n",
        "4. Retrieve data\n",
        "\n",
        "using command line options as [given here](https://cwiki.apache.org/confluence/display/hive/languagemanual+cli#)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKBG__HrKt9N",
        "outputId": "64a0f104-fa1c-4ad6-8272-5f5712e0e82e"
      },
      "source": [
        "!hive -e \"create database if not exists praxisDB;\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 67188175-4bde-4930-aeda-98190525eb04\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 928aaca8-f2e8-4f11-be15-f9cb9e145ec7\n",
            "OK\n",
            "Time taken: 1.36 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thoqjjcHZoLU",
        "outputId": "d314848e-5f54-4cd7-b90b-15149dc0239d"
      },
      "source": [
        "!hive -e \"show databases\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = a733a46f-4902-44db-a30a-0b60441ac1b9\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 029feb4b-0d92-43c0-bb85-a5308d133110\n",
            "OK\n",
            "default\n",
            "praxisdb\n",
            "Time taken: 1.543 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duhKRlsnax6U",
        "outputId": "710edb0b-45db-4801-bb96-3270e044860e"
      },
      "source": [
        "!hive -database praxisdb -e \"create table if not exists emp (name string, age int)\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 7f8c5eee-452b-4ebb-ab6d-a93322e08ab4\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 4d786d61-7430-4b80-885f-c4a6ad9aed28\n",
            "OK\n",
            "Time taken: 1.623 seconds\n",
            "OK\n",
            "Time taken: 1.811 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXhPGIBbd7v",
        "outputId": "8eefb622-5497-429e-8d54-cb0e8cfd54ae"
      },
      "source": [
        "!hive -database praxisdb -e \"show tables\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = f30cc1be-239a-49c1-a4b2-7dbeaabdc131\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = e711e2d9-b359-48b2-8516-31d40f9d04cb\n",
            "OK\n",
            "Time taken: 0.952 seconds\n",
            "OK\n",
            "emp\n",
            "Time taken: 0.456 seconds, Fetched: 1 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbc2fzSb4Po",
        "outputId": "27923b70-374e-4566-b832-5c9cb47360bc"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('naren', 70)\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = bdd73b83-a89b-48e9-a26e-23adee788e2e\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 971a9ce9-27fa-41c1-bb1d-e8335b7b8436\n",
            "OK\n",
            "Time taken: 1.079 seconds\n",
            "Query ID = root_20221007051423_59eb43be-6935-490c-a826-a72b7f4b72e1\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-10-07 05:14:29,359 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local66468923_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-10-07_05-14-23_111_5448332012303747772-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 7.452 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KvSvdgx7Hc",
        "outputId": "97046e03-ba96-4f73-93a3-7c03c745aaef"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('aditya', 49)\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = ca98eb23-bea8-426f-993a-1a4b3023f58f\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 6f43856a-9373-4791-8836-a886be96a2d4\n",
            "OK\n",
            "Time taken: 0.999 seconds\n",
            "Query ID = root_20221007051504_edc2f6c5-c725-4c9f-912d-81b2bc78f418\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-10-07 05:15:10,675 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local865613491_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-10-07_05-15-04_853_7144622512472081563-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 6.915 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxnPRbQclhP",
        "outputId": "c49b56e3-918c-4daa-e6f1-51712d15d613"
      },
      "source": [
        "!hive -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = f5022eea-43f3-4972-96a8-99e2495c6957\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 231ed47f-6482-43c3-ac85-b694f4d02da9\n",
            "OK\n",
            "Time taken: 1.172 seconds\n",
            "OK\n",
            "aditya\t49\n",
            "naren\t70\n",
            "Time taken: 2.853 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rwm36kUya6A",
        "outputId": "7c13d885-b0c0-404e-f34c-d8bce1357eec"
      },
      "source": [
        "# Silent Mode\n",
        "!hive -S -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = a0bf40ef-eed5-4327-973e-b306e7070f92\n",
            "Hive Session ID = fe2d3a83-1a77-4b51-bb3c-02809023fc75\n",
            "aditya\t49\n",
            "naren\t70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvIfuSAbkHJ9"
      },
      "source": [
        "## 2.7 Bulk Data Load from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSFFf3lwkMS0",
        "outputId": "72ffdc02-ce19-45fc-aed6-dc21da48ff8b"
      },
      "source": [
        "#drop table\n",
        "!hive -database praxisDB -e 'DROP table if exists eCommerce'\n",
        "#create table\n",
        "# Invoice Date is being treated as a STRING because input data is not correctly formatted\n",
        "!hive -database praxisDB -e \" \\\n",
        "CREATE TABLE eCommerce ( \\\n",
        "InvoiceNo varchar(10), \\\n",
        "StockCode varchar(10), \\\n",
        "Description varchar(50), \\\n",
        "Quantity int, \\\n",
        "InvoiceDate string, \\\n",
        "UnitPrice decimal(6,2), \\\n",
        "CustomerID varchar(10), \\\n",
        "Country varchar(15) \\\n",
        ") row format delimited fields terminated by ','; \\\n",
        "\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 163215b3-dfe9-4509-b4ba-eedc4c5dde8c\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 1ab744ac-c59c-48f1-b913-562135fd4807\n",
            "OK\n",
            "Time taken: 1.001 seconds\n",
            "OK\n",
            "Time taken: 0.152 seconds\n",
            "Hive Session ID = 30f4623a-5374-4000-abc3-b7c4113111c2\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = c8fc3096-faf6-41b8-bd9a-35ce1044d596\n",
            "OK\n",
            "Time taken: 1.031 seconds\n",
            "OK\n",
            "Time taken: 1.232 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4110Vjf-ktx6",
        "outputId": "f4dc60ea-71fa-4f71-d472-448510718d20"
      },
      "source": [
        "!hive -database praxisdb -e \"describe eCommerce\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = f8f6c026-9080-469a-a18d-39db63e877fa\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 0dd3bb97-d412-4bcf-95b2-6a145b7119ea\n",
            "OK\n",
            "Time taken: 1.002 seconds\n",
            "OK\n",
            "invoiceno           \tvarchar(10)         \t                    \n",
            "stockcode           \tvarchar(10)         \t                    \n",
            "description         \tvarchar(50)         \t                    \n",
            "quantity            \tint                 \t                    \n",
            "invoicedate         \tstring              \t                    \n",
            "unitprice           \tdecimal(6,2)        \t                    \n",
            "customerid          \tvarchar(10)         \t                    \n",
            "country             \tvarchar(15)         \t                    \n",
            "Time taken: 1.081 seconds, Fetched: 8 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfyabRo5pm7h"
      },
      "source": [
        "This data may not be clean and may have commas embedded in the CSV file. To see how clearn this look at this notebook : [Spark SQLContext HiveContext](https://github.com/prithwis/KKolab/blob/main/KK_C1_SparkSQL_SQLContext_HiveContext.ipynb) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqHKwLOIk67g",
        "outputId": "e26b3c23-a633-4e22-ef5b-3e3f5ac52ae3"
      },
      "source": [
        "#Data as CSV file\n",
        "!gdown https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV  # 2% data ~ 10K rows\n",
        "!gdown https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe  # 100% data ~ 500K rows"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV\n",
            "To: /content/eCommerce_02PC_2021.csv\n",
            "100% 917k/917k [00:00<00:00, 74.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe\n",
            "To: /content/eCommerce_Full_2021.csv\n",
            "100% 45.6M/45.6M [00:00<00:00, 87.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3M5Vl0NlNnQ",
        "outputId": "1d42cba5-3bc7-4c2a-c6e2-0bce6116ddf5"
      },
      "source": [
        "#remove the CRLF character from the end of the row if it exists\n",
        "!sed 's/\\r//' /content/eCommerce_Full_2021.csv > datafile.csv\n",
        "#!sed 's/\\r//' /content/eCommerce_02PC_2021.csv > datafile.csv\n",
        "# remove the first line containing headers from the file\n",
        "!sed -i -e \"1d\" datafile.csv    \n",
        "!head datafile.csv           "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n",
            "536365,71053,WHITE METAL LANTERN,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/2010 8:26,2.75,17850,United Kingdom\n",
            "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84029E,RED WOOLLY HOTTIE WHITE HEART.,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,22752,SET 7 BABUSHKA NESTING BOXES,2,12/1/2010 8:26,7.65,17850,United Kingdom\n",
            "536365,21730,GLASS STAR FROSTED T-LIGHT HOLDER,6,12/1/2010 8:26,4.25,17850,United Kingdom\n",
            "536366,22633,HAND WARMER UNION JACK,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536366,22632,HAND WARMER RED POLKA DOT,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536367,84879,ASSORTED COLOUR BIRD ORNAMENT,32,12/1/2010 8:34,1.69,13047,United Kingdom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XljU-WuElcUB",
        "outputId": "7f4d6a94-9df7-465f-fc09-a2daf0fca9e2"
      },
      "source": [
        "# delete all rows from table\n",
        "!hive -database praxisdb -e 'TRUNCATE TABLE eCommerce'\n",
        "# LOAD\n",
        "!hive -database praxisdb -e \"LOAD DATA LOCAL INPATH 'datafile.csv' INTO TABLE eCommerce\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 5cdd0d51-0151-481b-b7db-91a17079f760\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 89623963-dbbc-4a4b-966d-875ff5ce5c36\n",
            "OK\n",
            "Time taken: 1.061 seconds\n",
            "OK\n",
            "Time taken: 1.361 seconds\n",
            "Hive Session ID = 3a97f415-1a7e-42bb-86be-d60f3fdd18db\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 1e976604-960e-4c3e-b6d8-d28c0f9a80b2\n",
            "OK\n",
            "Time taken: 1.087 seconds\n",
            "Loading data to table praxisdb.ecommerce\n",
            "OK\n",
            "Time taken: 1.973 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRceNDPylu2U",
        "outputId": "e274ae2e-4b79-4feb-935b-e093108369c4"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select count(*) from eCommerce\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 06af94bc-c24c-46c6-863f-9d524d2cee74\n",
            "Hive Session ID = b841e9c5-082e-463c-a818-8d53fdd17b32\n",
            "541909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m977A2Jnl5mZ",
        "outputId": "8cd96ebe-6920-4fe7-c4fd-5bfd5cd21afc"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select * from eCommerce limit 30\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 32bcdbca-44a3-4224-be11-40eb2b1f097b\n",
            "Hive Session ID = 41806a24-ba94-4031-b7cf-6e134ffbfc4d\n",
            "536365\t85123A\tWHITE HANGING HEART T-LIGHT HOLDER\t6\t12/1/2010 8:26\t2.55\t17850\tUnited Kingdom\n",
            "536365\t71053\tWHITE METAL LANTERN\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84406B\tCREAM CUPID HEARTS COAT HANGER\t8\t12/1/2010 8:26\t2.75\t17850\tUnited Kingdom\n",
            "536365\t84029G\tKNITTED UNION FLAG HOT WATER BOTTLE\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84029E\tRED WOOLLY HOTTIE WHITE HEART.\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t22752\tSET 7 BABUSHKA NESTING BOXES\t2\t12/1/2010 8:26\t7.65\t17850\tUnited Kingdom\n",
            "536365\t21730\tGLASS STAR FROSTED T-LIGHT HOLDER\t6\t12/1/2010 8:26\t4.25\t17850\tUnited Kingdom\n",
            "536366\t22633\tHAND WARMER UNION JACK\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536366\t22632\tHAND WARMER RED POLKA DOT\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536367\t84879\tASSORTED COLOUR BIRD ORNAMENT\t32\t12/1/2010 8:34\t1.69\t13047\tUnited Kingdom\n",
            "536367\t22745\tPOPPY'S PLAYHOUSE BEDROOM \t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22748\tPOPPY'S PLAYHOUSE KITCHEN\t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22749\tFELTCRAFT PRINCESS CHARLOTTE DOLL\t8\t12/1/2010 8:34\t3.75\t13047\tUnited Kingdom\n",
            "536367\t22310\tIVORY KNITTED MUG COSY \t6\t12/1/2010 8:34\t1.65\t13047\tUnited Kingdom\n",
            "536367\t84969\tBOX OF 6 ASSORTED COLOUR TEASPOONS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536367\t22623\tBOX OF VINTAGE JIGSAW BLOCKS \t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536367\t22622\tBOX OF VINTAGE ALPHABET BLOCKS\t2\t12/1/2010 8:34\t9.95\t13047\tUnited Kingdom\n",
            "536367\t21754\tHOME BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21755\tLOVE BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21777\tRECIPE BOX WITH METAL HEART\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536367\t48187\tDOORMAT NEW ENGLAND\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536368\t22960\tJAM MAKING SET WITH JARS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536368\t22913\tRED COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22912\tYELLOW COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22914\tBLUE COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536369\t21756\tBATH BUILDING BLOCK WORD\t3\t12/1/2010 8:35\t5.95\t13047\tUnited Kingdom\n",
            "536370\t22728\tALARM CLOCK BAKELIKE PINK\t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22727\tALARM CLOCK BAKELIKE RED \t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22726\tALARM CLOCK BAKELIKE GREEN\t12\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t21724\tPANDA AND BUNNIES STICKER SHEET\t12\t12/1/2010 8:45\t0.85\t12583\tFrance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "print('signed off at  ',datetime.now(pytz.timezone('Asia/Kolkata')))"
      ],
      "metadata": {
        "id": "-CtmCPvi4jJ1",
        "outputId": "699ff288-1905-46ea-dd90-7035418bb9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signed off at   2022-10-07 10:58:20.965135+05:30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEShQrGRJio3"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}