{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B2 Hadoop and Hive",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/KK_B2_Hadoop_and_Hive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOvxIBi-IJ8G"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwjvirExIQAM"
      },
      "source": [
        "#Hive with Hadoop\n",
        "This notebook has all the codes / commands required to install Hadoop and Hive <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5y3g-ySDmZ"
      },
      "source": [
        "##Acknowledgements\n",
        "Hadoop Installation from [Anjaly Sam's Github Repository](https://github.com/anjalysam/Hadoop) <br>\n",
        "Hive Installation from [PhoenixNAP](https://phoenixnap.com/kb/install-hive-on-ubuntu) website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPIGP-mwKBD"
      },
      "source": [
        "#1 Hadoop\n",
        "Hadoop is a pre-requisite for Hive <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bT9M1yvyXG"
      },
      "source": [
        "## 1.1 Download, Install Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFZuorwF25e"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZAdD_cBMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2cee82-040e-4fea-ca96-d3b4c8315781"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "# Change the version number in this and subsequent cells\n",
        "#\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.2.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-25 06:26:23--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  27.7MB/s    in 23s     \n",
            "\n",
            "2022-04-25 06:26:46 (26.9 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6Dqbbrwqpe"
      },
      "source": [
        "## 1.2 Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUc19ZtcBG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba02e07b-f9b7-4876-a978-93230d9e9607"
      },
      "source": [
        "#To find the default Java path\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "!ls /usr/lib/jvm/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-11-openjdk-amd64/\n",
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez4T7Gs3RAn"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.2/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKOGAmCVhXZ4",
        "outputId": "feeb655f-870e-4396-b4bf-7204c1e1fbf2"
      },
      "source": [
        "!echo $PATH"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFgpWGLhdhl"
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# get current_path from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.2/bin/'\n",
        "os.environ[\"PATH\"] = new_path"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj00rPPZyEWZ"
      },
      "source": [
        "## 1.3 Test Hadoop Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf-zK7NcBDF"
      },
      "source": [
        "#Running Hadoop - Test RUN, not doing anything at all\n",
        "#!/usr/local/hadoop-3.3.0/bin/hadoop\n",
        "# UNCOMMENT the following line if you want to make sure that Hadoop is alive!\n",
        "#!hadoop"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3I6iqjGod-"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUlA5c3yRCx1"
      },
      "source": [
        "#2 Hive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pURJ-sKVsymi"
      },
      "source": [
        "## 2.1 Download, Install HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFsywGzPRaYp",
        "outputId": "bc8f4331-0c9b-4ca7-f779-da4c178462ba"
      },
      "source": [
        "# Download and Unzip the correct version and unzip\n",
        "!wget https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
        "!tar xzf apache-hive-3.1.2-bin.tar.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-25 06:31:49--  https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278813748 (266M) [application/x-gzip]\n",
            "Saving to: ‘apache-hive-3.1.2-bin.tar.gz’\n",
            "\n",
            "apache-hive-3.1.2-b 100%[===================>] 265.90M  25.8MB/s    in 11s     \n",
            "\n",
            "2022-04-25 06:32:00 (23.9 MB/s) - ‘apache-hive-3.1.2-bin.tar.gz’ saved [278813748/278813748]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq6QYCVetNED"
      },
      "source": [
        "## 2.2 Set Environment *Variables*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qROUu4vSdEU",
        "outputId": "a88414f5-ab2c-4062-a5d0-175072b9ef14"
      },
      "source": [
        "# Make sure that the version number is correct and is as downloaded\n",
        "os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NFES7SBYkUt",
        "outputId": "75189934-47b2-4ccd-deee-b0fb48f781e7"
      },
      "source": [
        "!echo $PATH"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3pKQ9PTBfR",
        "outputId": "d1eae8b6-8fa5-4deb-b5f5-a9170c1e19ba"
      },
      "source": [
        "# current_path is set from output of previous command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "current_path = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/'\n",
        "new_path = current_path+':/content/apache-hive-3.1.2-bin/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.2/bin/:/content/apache-hive-3.1.2-bin/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfiA2LItT_L2",
        "outputId": "d88075b4-1547-4892-9e4f-bdb5c98d09db"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HIVE_HOME"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.2/\n",
            "/content/apache-hive-3.1.2-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AryjHG4ltfEe"
      },
      "source": [
        "## 2.3 Set up HDFS Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dry58UPMVTat",
        "outputId": "2887fe0f-44f1-438e-f269-4f2660a4b1bf"
      },
      "source": [
        "!hdfs dfs -mkdir /tmp\n",
        "!hdfs dfs -chmod g+w /tmp\n",
        "#!hdfs dfs -ls /\n",
        "!hdfs dfs -mkdir -p /content/warehouse\n",
        "!hdfs dfs -chmod g+w /content/warehouse\n",
        "#!hdfs dfs -ls /content/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: `/tmp': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VrvjhfG2JXs"
      },
      "source": [
        "## 2.4 Initialise HIVE - note and fix errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLX7AvL8YLMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c1b05e-e58f-4e8f-ada1-0d1bc0ef51df"
      },
      "source": [
        "# TYPE this command, do not copy and paste. Non printing characters cause havoc \n",
        "# There will be two errors, that we will fix\n",
        "# UNCOMMENT the following line if you WISH TO SEE the errors\n",
        "!schematool -initSchema -dbType derby\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Metastore connection URL:\t jdbc:derby:;databaseName=metastore_db;create=true\n",
            "Metastore Connection Driver :\t org.apache.derby.jdbc.EmbeddedDriver\n",
            "Metastore connection User:\t APP\n",
            "Starting metastore schema initialization to 3.1.0\n",
            "Initialization script hive-schema-3.1.0.derby.sql\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Initialization script completed\n",
            "schemaTool completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v21CxgGLuJPQ"
      },
      "source": [
        "### 2.4.1 Fix One Warning, One Error \n",
        "SLF4J is duplicate, need to locate them and remove one <br>\n",
        "Guava jar version is low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Becy3BABuE8b",
        "outputId": "879f7914-2fca-4047-e682-f197a318dcc1"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HIVE_HOME/lib/*slf4j*"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/jul-to-slf4j-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-api-1.7.30.jar\n",
            "/usr/local/hadoop-3.3.2//share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar\n",
            "/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUomnHGu4kR"
      },
      "source": [
        "# removed the logging jar from Hive, retaining the Hadoop jar\n",
        "!mv /content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar ./"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwLAYh7TY4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2943a2-da35-4321-f189-1efcba3a1ab0"
      },
      "source": [
        "# guava jar needs to above v 20\n",
        "# https://stackoverflow.com/questions/45247193/nosuchmethoderror-com-google-common-base-preconditions-checkargumentzljava-lan\n",
        "!ls $HIVE_HOME/lib/gu*"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.2-bin/lib/guava-19.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpmyrbkZFad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d70a8d-085f-414c-f72a-c7780ce9fab9"
      },
      "source": [
        "# the one available with Hadoop is better, v 27\n",
        "!ls $HADOOP_HOME/share/hadoop/hdfs/lib/gu*"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2//share/hadoop/hdfs/lib/guava-27.0-jre.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ3Ex1vyZeZG"
      },
      "source": [
        "# Remove the Hive Guava and replace with Hadoop Guava\n",
        "!mv $HIVE_HOME/lib/guava-19.0.jar ./\n",
        "!cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdtNOXy8v4iD"
      },
      "source": [
        "##2.5 Initialize HIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tzw4XkApRg3",
        "outputId": "6388f98c-0eab-4e5c-b9da-110ba10959a5"
      },
      "source": [
        "#Type this command, dont copy-paste\n",
        "# Non printing characters inside the command will give totally illogical errors\n",
        "!schematool -initSchema -dbType derby"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metastore connection URL:\t jdbc:derby:;databaseName=metastore_db;create=true\n",
            "Metastore Connection Driver :\t org.apache.derby.jdbc.EmbeddedDriver\n",
            "Metastore connection User:\t APP\n",
            "Starting metastore schema initialization to 3.1.0\n",
            "Initialization script hive-schema-3.1.0.derby.sql\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Initialization script completed\n",
            "schemaTool completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALF720ewT_-"
      },
      "source": [
        "## 2.6 Test HIVE \n",
        "1. Create database\n",
        "2. Create table\n",
        "3. Insert data\n",
        "4. Retrieve data\n",
        "\n",
        "using command line options as [given here](https://cwiki.apache.org/confluence/display/hive/languagemanual+cli#)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKBG__HrKt9N",
        "outputId": "b05243c6-66a0-490c-d02c-169d4bb86648"
      },
      "source": [
        "!hive -e \"create database if not exists praxisDB;\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 8c99ba30-7a4a-4d9d-bdb5-c424095f50d3\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = c396d07d-67ca-444f-8349-b8220bb14eea\n",
            "OK\n",
            "Time taken: 1.402 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thoqjjcHZoLU",
        "outputId": "17a6d305-723a-4269-9171-07129de0b45e"
      },
      "source": [
        "!hive -e \"show databases\""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = b4e59be9-e626-4b03-b21c-99ac663ce43f\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 50c6ef5b-4072-49ae-a1b7-65304999ccf8\n",
            "OK\n",
            "default\n",
            "praxisdb\n",
            "Time taken: 1.498 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duhKRlsnax6U",
        "outputId": "dde2cd99-6397-4f63-b5ea-c2e47dde7708"
      },
      "source": [
        "!hive -database praxisdb -e \"create table if not exists emp (name string, age int)\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = a863d3a6-9271-4ae0-9f88-ba5478cb272d\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = d4ac14cb-5102-4583-a7d8-b9efe35f2d2d\n",
            "OK\n",
            "Time taken: 1.055 seconds\n",
            "OK\n",
            "Time taken: 1.387 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXhPGIBbd7v",
        "outputId": "9966a3ac-aa94-47b7-b835-0c2b94dd990b"
      },
      "source": [
        "!hive -database praxisdb -e \"show tables\""
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = d892479c-4410-4041-8965-bb5e2b5a585a\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = ae59892a-d876-4a2c-9ab0-1e63aa41393b\n",
            "OK\n",
            "Time taken: 1.018 seconds\n",
            "OK\n",
            "ecommerce\n",
            "emp\n",
            "Time taken: 0.576 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbc2fzSb4Po",
        "outputId": "4d46c777-8d99-4c3e-c2cc-a1ef1045eb74"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('naren', 70)\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = c1f24b57-6ca4-4c9f-bcb8-4cd73e24cf3c\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = c9dbe292-e6c0-4eac-98a8-3bc5c9f523c3\n",
            "OK\n",
            "Time taken: 1.029 seconds\n",
            "Query ID = root_20220425063641_887eb83f-affd-41a7-a469-781e056e280e\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-04-25 06:36:47,993 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local821392589_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-04-25_06-36-41_380_8467727518857374626-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 7.906 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KvSvdgx7Hc",
        "outputId": "ea1815e2-cb94-4c2b-b6b8-9f1d208a8ec1"
      },
      "source": [
        "!hive -database praxisdb -e \"insert into emp values ('aditya', 49)\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 5978b39f-f5b2-4f03-b281-2bb634f07c11\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 3241fba8-7886-4854-b7de-82e8675888fb\n",
            "OK\n",
            "Time taken: 0.991 seconds\n",
            "Query ID = root_20220425063708_2e5595dd-5ed2-4bf8-b525-4ec38bdfb2da\n",
            "Total jobs = 3\n",
            "Launching Job 1 out of 3\n",
            "Number of reduce tasks determined at compile time: 1\n",
            "In order to change the average load for a reducer (in bytes):\n",
            "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
            "In order to limit the maximum number of reducers:\n",
            "  set hive.exec.reducers.max=<number>\n",
            "In order to set a constant number of reducers:\n",
            "  set mapreduce.job.reduces=<number>\n",
            "Job running in-process (local Hadoop)\n",
            "2022-04-25 06:37:14,297 Stage-1 map = 100%,  reduce = 100%\n",
            "Ended Job = job_local646930835_0001\n",
            "Stage-4 is selected by condition resolver.\n",
            "Stage-3 is filtered out by condition resolver.\n",
            "Stage-5 is filtered out by condition resolver.\n",
            "Moving data to directory file:/user/hive/warehouse/praxisdb.db/emp/.hive-staging_hive_2022-04-25_06-37-08_206_4670979060518316165-1/-ext-10000\n",
            "Loading data to table praxisdb.emp\n",
            "MapReduce Jobs Launched: \n",
            "Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\n",
            "Total MapReduce CPU Time Spent: 0 msec\n",
            "OK\n",
            "Time taken: 7.228 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxnPRbQclhP",
        "outputId": "4faa6de8-9e8a-47b9-c5e6-3533c8289eb8"
      },
      "source": [
        "!hive -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 78a7972f-ebc9-4e1c-a77a-b43f0690f4ed\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 743758ef-f8e6-4305-b2a6-a25de4ece001\n",
            "OK\n",
            "Time taken: 1.015 seconds\n",
            "OK\n",
            "aditya\t49\n",
            "naren\t70\n",
            "Time taken: 2.945 seconds, Fetched: 2 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rwm36kUya6A",
        "outputId": "a7a1e695-fec2-44da-c535-e52a33f5df8a"
      },
      "source": [
        "# Silent Mode\n",
        "!hive -S -database praxisdb -e \"select * from emp\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 0aa12930-5e00-436d-9e19-98d9a4caaef0\n",
            "Hive Session ID = 33ef2005-48ee-4038-9503-44bf71883029\n",
            "aditya\t49\n",
            "naren\t70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvIfuSAbkHJ9"
      },
      "source": [
        "## 2.7 Bulk Data Load from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSFFf3lwkMS0",
        "outputId": "46c31deb-dd0a-4134-cbaa-bbee8ef2a3bd"
      },
      "source": [
        "#drop table\n",
        "!hive -database praxisDB -e 'DROP table if exists eCommerce'\n",
        "#create table\n",
        "# Invoice Date is being treated as a STRING because input data is not correctly formatted\n",
        "!hive -database praxisDB -e \" \\\n",
        "CREATE TABLE eCommerce ( \\\n",
        "InvoiceNo varchar(10), \\\n",
        "StockCode varchar(10), \\\n",
        "Description varchar(50), \\\n",
        "Quantity int, \\\n",
        "InvoiceDate string, \\\n",
        "UnitPrice decimal(6,2), \\\n",
        "CustomerID varchar(10), \\\n",
        "Country varchar(15) \\\n",
        ") row format delimited fields terminated by ','; \\\n",
        "\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 103b087b-2e12-49bf-9b97-6bb7b72b3341\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 76aca0ca-fb78-4021-9017-39c3e935d657\n",
            "OK\n",
            "Time taken: 1.029 seconds\n",
            "OK\n",
            "Time taken: 0.143 seconds\n",
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 7ee532bc-5e44-4ae2-ad9d-9ac954c8db3a\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 72043a73-792d-45ce-9666-3f2f02e6b6fa\n",
            "OK\n",
            "Time taken: 1.025 seconds\n",
            "OK\n",
            "Time taken: 1.247 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4110Vjf-ktx6",
        "outputId": "46b55689-88ef-44b8-9add-68b270d40482"
      },
      "source": [
        "!hive -database praxisdb -e \"describe eCommerce\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 80ba7e53-ab3c-4411-9466-e4ab7770f7f3\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 67854596-1ec0-48ce-a526-7064061026b3\n",
            "OK\n",
            "Time taken: 1.037 seconds\n",
            "OK\n",
            "invoiceno           \tvarchar(10)         \t                    \n",
            "stockcode           \tvarchar(10)         \t                    \n",
            "description         \tvarchar(50)         \t                    \n",
            "quantity            \tint                 \t                    \n",
            "invoicedate         \tstring              \t                    \n",
            "unitprice           \tdecimal(6,2)        \t                    \n",
            "customerid          \tvarchar(10)         \t                    \n",
            "country             \tvarchar(15)         \t                    \n",
            "Time taken: 1.051 seconds, Fetched: 8 row(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfyabRo5pm7h"
      },
      "source": [
        "This data may not be clean and may have commas embedded in the CSV file. To see how clearn this look at this notebook : [Spark SQLContext HiveContext](https://github.com/prithwis/KKolab/blob/main/KK_C1_SparkSQL_SQLContext_HiveContext.ipynb) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqHKwLOIk67g",
        "outputId": "573b9cbe-9dc0-4c74-cb73-46d0014769c7"
      },
      "source": [
        "#Data as CSV file\n",
        "!gdown https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV  # 2% data ~ 10K rows\n",
        "!gdown https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe  # 100% data ~ 500K rows"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJH24ZZaiJrEKValD--UtyFcWl7UanwV\n",
            "To: /content/eCommerce_02PC_2021.csv\n",
            "100% 917k/917k [00:00<00:00, 103MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g7mJ0v4fkERW0HWc1eq-SHs_jvQ0N2Oe\n",
            "To: /content/eCommerce_Full_2021.csv\n",
            "100% 45.6M/45.6M [00:00<00:00, 125MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3M5Vl0NlNnQ",
        "outputId": "114f7803-8c7d-417c-c185-2fbbcfb7b640"
      },
      "source": [
        "#remove the CRLF character from the end of the row if it exists\n",
        "!sed 's/\\r//' /content/eCommerce_Full_2021.csv > datafile.csv\n",
        "#!sed 's/\\r//' /content/eCommerce_02PC_2021.csv > datafile.csv\n",
        "# remove the first line containing headers from the file\n",
        "!sed -i -e \"1d\" datafile.csv    \n",
        "!head datafile.csv           "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n",
            "536365,71053,WHITE METAL LANTERN,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/2010 8:26,2.75,17850,United Kingdom\n",
            "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,84029E,RED WOOLLY HOTTIE WHITE HEART.,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
            "536365,22752,SET 7 BABUSHKA NESTING BOXES,2,12/1/2010 8:26,7.65,17850,United Kingdom\n",
            "536365,21730,GLASS STAR FROSTED T-LIGHT HOLDER,6,12/1/2010 8:26,4.25,17850,United Kingdom\n",
            "536366,22633,HAND WARMER UNION JACK,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536366,22632,HAND WARMER RED POLKA DOT,6,12/1/2010 8:28,1.85,17850,United Kingdom\n",
            "536367,84879,ASSORTED COLOUR BIRD ORNAMENT,32,12/1/2010 8:34,1.69,13047,United Kingdom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XljU-WuElcUB",
        "outputId": "ad490e07-57d2-4371-817b-9a8ac30c1057"
      },
      "source": [
        "# delete all rows from table\n",
        "!hive -database praxisdb -e 'TRUNCATE TABLE eCommerce'\n",
        "# LOAD\n",
        "!hive -database praxisdb -e \"LOAD DATA LOCAL INPATH 'datafile.csv' INTO TABLE eCommerce\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 5ecc5dac-e715-4a89-b923-a34684ccb18f\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = ade734cf-54fc-4176-acf7-c612df3690b9\n",
            "OK\n",
            "Time taken: 0.983 seconds\n",
            "OK\n",
            "Time taken: 1.392 seconds\n",
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 0bd10c84-4712-4ce5-bc7d-3d362e0660b7\n",
            "\n",
            "Logging initialized using configuration in jar:file:/content/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true\n",
            "Hive Session ID = 3f09628b-1148-414f-a66b-131ff461abe3\n",
            "OK\n",
            "Time taken: 1.048 seconds\n",
            "Loading data to table praxisdb.ecommerce\n",
            "OK\n",
            "Time taken: 2.171 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRceNDPylu2U",
        "outputId": "7d19dfc5-00d6-476f-87fa-5020b6e7bea1"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select count(*) from eCommerce\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/content/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.2/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
            "Hive Session ID = 34ca9259-bc52-4470-9f3e-deb3667aec89\n",
            "Hive Session ID = aa057263-5c77-4eb3-8f16-9a21591658f2\n",
            "541909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m977A2Jnl5mZ",
        "outputId": "e1168540-b288-4485-8a8d-6f2035cb78db"
      },
      "source": [
        "!hive -S -database praxisdb -e \"select * from eCommerce limit 30\""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hive Session ID = 37914188-73e8-48b0-b5e4-5c027dd9674d\n",
            "Hive Session ID = 538ccab8-ec0f-4773-9a72-3f9ff963a7de\n",
            "536365\t85123A\tWHITE HANGING HEART T-LIGHT HOLDER\t6\t12/1/2010 8:26\t2.55\t17850\tUnited Kingdom\n",
            "536365\t71053\tWHITE METAL LANTERN\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84406B\tCREAM CUPID HEARTS COAT HANGER\t8\t12/1/2010 8:26\t2.75\t17850\tUnited Kingdom\n",
            "536365\t84029G\tKNITTED UNION FLAG HOT WATER BOTTLE\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t84029E\tRED WOOLLY HOTTIE WHITE HEART.\t6\t12/1/2010 8:26\t3.39\t17850\tUnited Kingdom\n",
            "536365\t22752\tSET 7 BABUSHKA NESTING BOXES\t2\t12/1/2010 8:26\t7.65\t17850\tUnited Kingdom\n",
            "536365\t21730\tGLASS STAR FROSTED T-LIGHT HOLDER\t6\t12/1/2010 8:26\t4.25\t17850\tUnited Kingdom\n",
            "536366\t22633\tHAND WARMER UNION JACK\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536366\t22632\tHAND WARMER RED POLKA DOT\t6\t12/1/2010 8:28\t1.85\t17850\tUnited Kingdom\n",
            "536367\t84879\tASSORTED COLOUR BIRD ORNAMENT\t32\t12/1/2010 8:34\t1.69\t13047\tUnited Kingdom\n",
            "536367\t22745\tPOPPY'S PLAYHOUSE BEDROOM \t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22748\tPOPPY'S PLAYHOUSE KITCHEN\t6\t12/1/2010 8:34\t2.10\t13047\tUnited Kingdom\n",
            "536367\t22749\tFELTCRAFT PRINCESS CHARLOTTE DOLL\t8\t12/1/2010 8:34\t3.75\t13047\tUnited Kingdom\n",
            "536367\t22310\tIVORY KNITTED MUG COSY \t6\t12/1/2010 8:34\t1.65\t13047\tUnited Kingdom\n",
            "536367\t84969\tBOX OF 6 ASSORTED COLOUR TEASPOONS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536367\t22623\tBOX OF VINTAGE JIGSAW BLOCKS \t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536367\t22622\tBOX OF VINTAGE ALPHABET BLOCKS\t2\t12/1/2010 8:34\t9.95\t13047\tUnited Kingdom\n",
            "536367\t21754\tHOME BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21755\tLOVE BUILDING BLOCK WORD\t3\t12/1/2010 8:34\t5.95\t13047\tUnited Kingdom\n",
            "536367\t21777\tRECIPE BOX WITH METAL HEART\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536367\t48187\tDOORMAT NEW ENGLAND\t4\t12/1/2010 8:34\t7.95\t13047\tUnited Kingdom\n",
            "536368\t22960\tJAM MAKING SET WITH JARS\t6\t12/1/2010 8:34\t4.25\t13047\tUnited Kingdom\n",
            "536368\t22913\tRED COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22912\tYELLOW COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536368\t22914\tBLUE COAT RACK PARIS FASHION\t3\t12/1/2010 8:34\t4.95\t13047\tUnited Kingdom\n",
            "536369\t21756\tBATH BUILDING BLOCK WORD\t3\t12/1/2010 8:35\t5.95\t13047\tUnited Kingdom\n",
            "536370\t22728\tALARM CLOCK BAKELIKE PINK\t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22727\tALARM CLOCK BAKELIKE RED \t24\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t22726\tALARM CLOCK BAKELIKE GREEN\t12\t12/1/2010 8:45\t3.75\t12583\tFrance\n",
            "536370\t21724\tPANDA AND BUNNIES STICKER SHEET\t12\t12/1/2010 8:45\t0.85\t12583\tFrance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEShQrGRJio3"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}