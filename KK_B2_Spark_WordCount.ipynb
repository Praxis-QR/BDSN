{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B2 Spark WordCount",
      "provenance": [],
      "collapsed_sections": [
        "W2QOKe1NRHn4",
        "sRvq6-Cd5cwS",
        "-tVgOWHgpc0W",
        "_2HO3H2WkkDC",
        "G9QnYzQBmqC6"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithwis/KKolab/blob/main/KK_B2_Spark_WordCount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj93_nN2wPV1"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOI8k9qicmu"
      },
      "source": [
        "# Install, Initialise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIjVxBSKIDsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de3fd91-d2cd-4d8d-f2db-1c907508d3c9"
      },
      "source": [
        "!apt update > /dev/null\n",
        "!apt install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAgQ-0fGhxWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45aab79-29c0-4fba-c3d1-aff1123db48b"
      },
      "source": [
        "# Get latest and correct version of Spark\n",
        "#\n",
        "# if the current version of Spark is not used, there may be errors\n",
        "# check here for current versions http://apache.osuosl.org/spark\n",
        "#\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.2.2/spark-2.2.2-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!wget -q http://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "\n",
        "#!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#!pip install -q findspark\n",
        "!pip install -q pyspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 59 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ClRT_Ari2Ys"
      },
      "source": [
        "# findspark route is no more required\n",
        "#import findspark\n",
        "#findspark.init()\n",
        "#\n",
        "#findspark.init('/content/spark-2.2.2-bin-hadoop2.7')\n",
        "#\n",
        "# https://stackoverflow.com/questions/42223498/findspark-init-indexerror-list-index-out-of-range-error\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm3XlHanNEq7"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "#spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# note UI port switched from default 4040 to 4050 to avoid clash with ngrok\n",
        "spark = SparkSession.builder.master(\"local[*]\").config('spark.ui.port', '4050').getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "931FrA2jfeXf"
      },
      "source": [
        "sc = spark.sparkContext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsSE4GKBiwf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "4d21217a-ec72-4e87-ecfc-45db158a18fd"
      },
      "source": [
        "# The spark Console UI is available in the link that will be displayed in this cell. \n",
        "# If you do not wish to use the Console, you may skip the Tunnel part\n",
        "sc"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ac0d2b2e851e:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2QOKe1NRHn4"
      },
      "source": [
        "##Tunnel with ngrok <br>\n",
        "This part required ONLY if you need to access Spark Console<br>\n",
        "To get you ngrok token please visit https://dashboard.ngrok.com/login <br>\n",
        "and create a free account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG1ZwJ8yehyw"
      },
      "source": [
        "###Loading ngrok token from GDrive<br>\n",
        "this part may be skipped if ngrok can be placed directly in one of the two next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7uFjFW9RU9L",
        "outputId": "263a711c-309f-4409-dcc3-bb07afe11ab5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsCxPFhjRqSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64aed300-a46b-486b-cdf7-aabdcdc48364"
      },
      "source": [
        "#!ls /content/drive/'My Drive'/Praxis/'Course - DevOps'/'Advanced Colab'/\n",
        "!ls /content/drive/'My Drive'/Praxis/WebCredentials/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clevercloudMongoDB.py  QuandlApiRegistrations_praxis.txt\n",
            "cleverCloud.py\t       QuandlApiRegistrations.txt\n",
            "db4freeCredentials.py  sqlCredentials_020221.py\n",
            "ngrokToken.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a48D9kHyR9gI"
      },
      "source": [
        "#!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/'Advanced Colab'/ngrokToken.py .\n",
        "!cp /content/drive/'My Drive'/Praxis/WebCredentials/ngrokToken.py ."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXb94HvLSSBb"
      },
      "source": [
        "# credential file for Prithwis Mukerjee\n",
        "# this file needs to be uploaded into the VM\n",
        "\n",
        "from ngrokToken import ngrokToken\n",
        "\n",
        "#for the sake of privacy\n",
        "#the following credentials need to be stored in a text file called ngrokToken.py\n",
        "#in the format given below\n",
        "#in the Colab VM\n",
        "\n",
        "#otherwise, the values can be directly placed here\n",
        "\n",
        "#ngrokToken = 'xxxxxxxxxxxxxxx'   # uncomment this line and place your own credentials here\n",
        "#token is available at https://dashboard.ngrok.com/get-started/setup\n",
        "\n",
        "\n",
        "#print(ngrokToken)\n",
        "ngrokTokenCmd = 'ngrok authtoken '+ngrokToken"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twDJK8Wzb6yd"
      },
      "source": [
        "###ngrok - native <br>\n",
        "has been having problems <br>\n",
        "this code adapted from https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/?unapproved=164287&moderation-hash=399998d65a0f1425c41aa2979e873387#comment-164287 <br>\n",
        "DEPRECATED - DO NOT USE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaCo9yVIcRej"
      },
      "source": [
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO04Lp9YcZEL"
      },
      "source": [
        "#!./ngrok authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "#get_ipython().system_raw(ngrokTokenCmd)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia0D9fHtRs1f"
      },
      "source": [
        "#!apt-get install jq > /dev/null"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_zKdINeuI3"
      },
      "source": [
        "#!./ngrok http 4050 &                       # -- causes problems"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFM4kdSljCo_"
      },
      "source": [
        "#get_ipython().system_raw('./ngrok http 4050 &')\n",
        "#!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk3jZ8lfSddJ"
      },
      "source": [
        "#!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].public_url\n",
        "#!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].config.addr"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuCKEn_dsfkm"
      },
      "source": [
        "###ngrok - python wrapper <br>\n",
        "this code adapted from https://towardsdatascience.com/quickly-share-ml-webapps-from-google-colab-using-ngrok-for-free-ae899ca2661a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sWPM5QvtS4B",
        "outputId": "69ed328b-e6f7-4936-fa00-92205c40c4ae"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.0.6.tar.gz (746 kB)\n",
            "\u001b[K     |████████████████████████████████| 746 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.6-py3-none-any.whl size=19262 sha256=0e6e466370fe6a7ac3eec6e90d68345bc4f196aee60f04d090fdea0bdbf0bb32\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/8c/c4/8d9cbca4fa19bf64887b4a91914194bb9033f1a7cbb344d5ab\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0ssMRt36k4"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "# you may place the token directly here\n",
        "#!ngrok authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "get_ipython().system_raw(ngrokTokenCmd)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU_KntEetijL"
      },
      "source": [
        "# Open a HTTP tunnel on the default port 80\n",
        "#public_url = ngrok.connect(port = '4050')\n",
        "public_url = ngrok.connect(4050)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ysgjHbtozr",
        "outputId": "cc622999-17a2-49f6-e525-588cf2623fc8"
      },
      "source": [
        "#This is where the Spark Console UI will be visible\n",
        "public_url"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://180f086a99fc.ngrok.io\" -> \"http://localhost:4050\">"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL_D5j-oOn2V"
      },
      "source": [
        "The next four cells are not required. Mainly used to check on the status of the Tunnel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Ne_XhzuDGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3226a6f6-969b-4356-b824-0816d04035c5"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"tunnels\":[{\"name\":\"http-4050-07606024-3b0c-4c56-ba95-4dc25e5c106c\",\"uri\":\"/api/tunnels/http-4050-07606024-3b0c-4c56-ba95-4dc25e5c106c\",\"public_url\":\"https://e2fd5c9fb145.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}},{\"name\":\"http-4050-07606024-3b0c-4c56-ba95-4dc25e5c106c (http)\",\"uri\":\"/api/tunnels/http-4050-07606024-3b0c-4c56-ba95-4dc25e5c106c%20%28http%29\",\"public_url\":\"http://e2fd5c9fb145.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO66r_yEftBC"
      },
      "source": [
        "#!ngrok help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tQPpQ8q09V",
        "outputId": "f0e9a5df-2c68-4352-af7b-49b454f4ecdc"
      },
      "source": [
        "!ps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:01 node\n",
            "     17 ?        00:00:00 tail\n",
            "     55 ?        00:00:01 jupyter-noteboo\n",
            "     56 ?        00:00:00 dap_multiplexer\n",
            "     66 ?        00:00:03 python3\n",
            "     86 ?        00:00:00 python3\n",
            "   1074 ?        00:00:09 java\n",
            "   1171 ?        00:00:00 bash\n",
            "   1172 ?        00:00:00 drive\n",
            "   1173 ?        00:00:00 grep\n",
            "   1220 ?        00:00:00 fusermount <defunct>\n",
            "   1246 ?        00:00:00 drive\n",
            "   1299 ?        00:00:00 bash\n",
            "   1300 ?        00:00:00 tail\n",
            "   1301 ?        00:00:00 python3\n",
            "   1345 ?        00:00:00 ngrok\n",
            "   1361 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkMV2GxrI3L"
      },
      "source": [
        "!kill -9 1219"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKbXwFgI8WW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBb0xKLi9BW"
      },
      "source": [
        "# Data Input - Three options, use only 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRvq6-Cd5cwS"
      },
      "source": [
        "##Local Machine\n",
        "Please upload a .txt file from your desktop to the VM using the upload feature of Colab. Without this, this set of commands will not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmB_erdoijn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856674a6-fa6f-44c2-ee12-c330bf60f7f5"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 223496\n",
            "drwx------  6 root root      4096 Aug 21 00:59 drive\n",
            "-rw-------  1 root root        64 Aug 21 00:59 ngrokToken.py\n",
            "drwxr-xr-x  2 root root      4096 Aug 21 00:59 __pycache__\n",
            "drwxr-xr-x  1 root root      4096 Aug 13 13:35 sample_data\n",
            "drwxr-xr-x 13 1000 1000      4096 May 24 04:45 spark-3.1.2-bin-hadoop3.2\n",
            "-rw-r--r--  1 root root 228834641 May 24 05:01 spark-3.1.2-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cetfRq2hToE"
      },
      "source": [
        "textRDD = sc.textFile(\"CY-033-28May2020-TextFile.txt\")\n",
        "#textRDD = sc.textFile(\"hobbit.txt\")\n",
        "#textRDD = spark.read.text('hobbit.txt').rdd\n",
        "# for an explanation of the alternate way to read text files\n",
        "# see this https://stackoverflow.com/questions/52665353/reading-a-text-file-in-spark/52669632#52669632"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiDK866KhToY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb7d6d6-6908-499e-907b-53e926a5c5a7"
      },
      "source": [
        "print (textRDD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CY-033-28May2020-TextFile.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylf23XX_o3m2"
      },
      "source": [
        "#textRDD.take(50)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVgOWHgpc0W"
      },
      "source": [
        "##Google Drive - Mount\n",
        "In this case, you can mount or connect Google drive and pull out a txt file from there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLUlMVwGpc0M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2QgW3PpfesD"
      },
      "source": [
        "#!ls /content/drive/\"My Drive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XHQchlpc0E"
      },
      "source": [
        "!ls /content/drive/\"My Drive\"/Praxis/\"Course - Big Data Spark\"/WordCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slfM2Xgcpcz0"
      },
      "source": [
        "!cat /content/drive/\"My Drive\"/Praxis/\"Course - Big Data Spark\"/WordCount/hobbit2.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luNYr9g-pczi"
      },
      "source": [
        "#textRDD = spark.read.text(\"/content/drive/My Drive/Praxis/Course - Big Data Spark/WordCount/hobbit2.txt\").rdd\n",
        "textRDD = sc.textFile(\"/content/drive/My Drive/Praxis/Course - Big Data Spark/WordCount/hobbit2.txt\")\n",
        "# for an explanation of the alternate way to read text files\n",
        "# see this https://stackoverflow.com/questions/52665353/reading-a-text-file-in-spark/52669632#52669632"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN6ZJ9v3pczT"
      },
      "source": [
        "textRDD.take(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0spX8yVNMyZw"
      },
      "source": [
        "##Google Drive - GDown\n",
        "In this case, a file that has universal read access privileges is pulled from Google Drive without the need to login in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvA6zv4fM1fc",
        "outputId": "87092ed7-ab37-4a1e-d620-e724d8146e8a"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1RELUMtExjMTSfoWF765Hr8JwNCSL7AgH"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RELUMtExjMTSfoWF765Hr8JwNCSL7AgH\n",
            "To: /content/hobbit.txt\n",
            "\r  0% 0.00/221 [00:00<?, ?B/s]\r100% 221/221 [00:00<00:00, 98.1kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO61epWsOBUP"
      },
      "source": [
        "textRDD = sc.textFile(\"hobbit.txt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zykb54rCOLe3",
        "outputId": "5909a40d-708c-4109-91b9-c8d3939366cd"
      },
      "source": [
        "textRDD.take(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The king beneath the mountain',\n",
              " 'The king of carven stone',\n",
              " 'The lord of silver fountain',\n",
              " 'Shall come unto his own',\n",
              " 'His throne shall be upholden']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2HO3H2WkkDC"
      },
      "source": [
        "# Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAvPRM1-kqJo"
      },
      "source": [
        "from operator import add"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Np0nEJhTpK"
      },
      "source": [
        "#def tokenize1(textz):\n",
        "#    return textz.value.split()\n",
        "def tokenize2(textz):\n",
        "    return textz.split()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7fP_I0OhTpa"
      },
      "source": [
        "wordsRDD = textRDD.flatMap(tokenize2)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl9ogplR7EGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1b7b0f-47ed-472b-c3bf-a3e816d05aa6"
      },
      "source": [
        "print(wordsRDD)\n",
        "wordsRDD.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PythonRDD[4] at RDD at PythonRDD.scala:53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'king',\n",
              " 'beneath',\n",
              " 'the',\n",
              " 'mountain',\n",
              " 'The',\n",
              " 'king',\n",
              " 'of',\n",
              " 'carven',\n",
              " 'stone']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac8Rb_Uiooqs"
      },
      "source": [
        "#wordsRDD.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMCcwZrxhTp8"
      },
      "source": [
        "wc = wordsRDD.map(lambda x: (x,1))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qbQGoyhTqQ"
      },
      "source": [
        "#print (wc.toDebugString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcIoomB-hTqi"
      },
      "source": [
        "counts = wc.reduceByKey(add)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9ODw1hXhTq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874e3f18-234f-4241-c9f8-5a59707580d4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t       __pycache__\t\t  spark-3.1.2-bin-hadoop3.2.tgz\n",
            "hobbit.txt     sample_data\n",
            "ngrokToken.py  spark-3.1.2-bin-hadoop3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5683u2uKhTrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a3e12f-aad2-4540-95f8-158fe6ddabef"
      },
      "source": [
        "# If running a program for the second time, the output directory needs to be deleted\n",
        "!rm -r hobbit-Out"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'hobbit-Out': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wydu9UDDhTro"
      },
      "source": [
        "counts.saveAsTextFile(\"hobbit-Out\")\n",
        "#counts.saveAsTextFile(\"CY-Out\")\n",
        "#counts.collect()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9QnYzQBmqC6"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ac3dQ2VmYda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065c133d-6d7d-4029-ba68-f3045e2bc7b9"
      },
      "source": [
        "# Output is visble here\n",
        "#!ls hobbit-Out\n",
        "!ls hobbit-Out"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part-00000  part-00001\t_SUCCESS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMkcg01rnBR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b882b2e-b37c-4876-adc1-de2f179f792d"
      },
      "source": [
        "#!cat hobbit-Out/part-00001\n",
        "!cat hobbit-Out/part-00001\n",
        "#!cat CY-Out/part-00000"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('the', 1)\n",
            "('mountain', 1)\n",
            "('carven', 1)\n",
            "('lord', 1)\n",
            "('Shall', 1)\n",
            "('come', 1)\n",
            "('unto', 1)\n",
            "('His', 3)\n",
            "('shall', 3)\n",
            "('be', 2)\n",
            "('golden', 1)\n",
            "('To', 1)\n",
            "('songs', 1)\n",
            "('your', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smdrOXSTiSPp"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZcQeS1hTuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1e075ce1-1db4-4bdc-d129-ca1d38f8048d"
      },
      "source": [
        "files.download(\"hobbit-Out/part-00000\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d748ce3a-396c-403a-bcea-bb81bfcbae81\", \"part-00000\", 210)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKTZezaqMK_0"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}